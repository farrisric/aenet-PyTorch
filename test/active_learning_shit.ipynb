{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/farri002/miniconda3/envs/tyxe/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH LOSS 0001] loss: 193.0858\n",
      "[EPOCH RMSD 0001] loss: 215191.6212\n",
      "[EPOCH LOSS 0101] loss: 3.3805\n",
      "[EPOCH LOSS 0201] loss: 3.2439\n",
      "[EPOCH LOSS 0301] loss: 3.1360\n",
      "[EPOCH LOSS 0401] loss: 3.7334\n",
      "[EPOCH LOSS 0501] loss: 4.1230\n",
      "[EPOCH LOSS 0601] loss: 4.9404\n",
      "[EPOCH LOSS 0701] loss: 2.6198\n",
      "[EPOCH LOSS 0801] loss: 2.9549\n",
      "[EPOCH LOSS 0901] loss: 2.6255\n",
      "[EPOCH LOSS 1001] loss: 2.5830\n",
      "[EPOCH RMSD 1001] loss: 839.4378\n",
      "[EPOCH LOSS 1101] loss: 2.8438\n",
      "[EPOCH LOSS 1201] loss: 2.9262\n",
      "[EPOCH LOSS 1301] loss: 2.7728\n",
      "[EPOCH LOSS 1401] loss: 9.3064\n",
      "[EPOCH LOSS 1501] loss: 4.4778\n",
      "[EPOCH LOSS 1601] loss: 2.5190\n",
      "[EPOCH LOSS 1701] loss: 2.5377\n",
      "[EPOCH LOSS 1801] loss: 3.1116\n",
      "[EPOCH LOSS 1901] loss: 3.2372\n",
      "[EPOCH LOSS 2001] loss: 3.0098\n",
      "[EPOCH RMSD 2001] loss: 711.3995\n",
      "[EPOCH LOSS 2101] loss: 4.8444\n",
      "[EPOCH LOSS 2201] loss: 3.1050\n",
      "[EPOCH LOSS 2301] loss: 2.5494\n",
      "[EPOCH LOSS 2401] loss: 3.3365\n",
      "[EPOCH LOSS 2501] loss: 3.0020\n",
      "[EPOCH LOSS 2601] loss: 2.5169\n",
      "[EPOCH LOSS 2701] loss: 5.5828\n",
      "[EPOCH LOSS 2801] loss: 5.0413\n",
      "[EPOCH LOSS 2901] loss: 2.4341\n",
      "[EPOCH LOSS 3001] loss: 4.9795\n",
      "[EPOCH RMSD 3001] loss: 481.5653\n",
      "[EPOCH LOSS 3101] loss: 2.2784\n",
      "[EPOCH LOSS 3201] loss: 2.2445\n",
      "[EPOCH LOSS 3301] loss: 2.2399\n",
      "[EPOCH LOSS 3401] loss: 2.1283\n",
      "[EPOCH LOSS 3501] loss: 8.1626\n",
      "[EPOCH LOSS 3601] loss: 2.7170\n",
      "[EPOCH LOSS 3701] loss: 3.5968\n",
      "[EPOCH LOSS 3801] loss: 2.2947\n",
      "[EPOCH LOSS 3901] loss: 3.0507\n",
      "[EPOCH LOSS 4001] loss: 2.5431\n",
      "[EPOCH RMSD 4001] loss: 300.4186\n",
      "[EPOCH LOSS 4101] loss: 2.0500\n",
      "[EPOCH LOSS 4201] loss: 2.3842\n",
      "[EPOCH LOSS 4301] loss: 2.3657\n",
      "[EPOCH LOSS 4401] loss: 2.0313\n",
      "[EPOCH LOSS 4501] loss: 1.7141\n",
      "[EPOCH LOSS 4601] loss: 1.8585\n",
      "[EPOCH LOSS 4701] loss: 6.2692\n",
      "[EPOCH LOSS 4801] loss: 2.1523\n",
      "[EPOCH LOSS 4901] loss: 1.7385\n",
      "[EPOCH LOSS 5001] loss: 1.7651\n",
      "[EPOCH RMSD 5001] loss: 199.6032\n",
      "[EPOCH LOSS 5101] loss: 1.9801\n",
      "[EPOCH LOSS 5201] loss: 9.8496\n",
      "[EPOCH LOSS 5301] loss: 12.8692\n",
      "[EPOCH LOSS 5401] loss: 2.0346\n",
      "[EPOCH LOSS 5501] loss: 1.9950\n",
      "[EPOCH LOSS 5601] loss: 1.8057\n",
      "[EPOCH LOSS 5701] loss: 1.6412\n",
      "[EPOCH LOSS 5801] loss: 1.7388\n",
      "[EPOCH LOSS 5901] loss: 1.6867\n",
      "[EPOCH LOSS 6001] loss: 1.7348\n",
      "[EPOCH RMSD 6001] loss: 211.0490\n",
      "[EPOCH LOSS 6101] loss: 2.2468\n",
      "[EPOCH LOSS 6201] loss: 2.2873\n",
      "[EPOCH LOSS 6301] loss: 1.9994\n",
      "[EPOCH LOSS 6401] loss: 1.5237\n",
      "[EPOCH LOSS 6501] loss: 1.4893\n",
      "[EPOCH LOSS 6601] loss: 1.6165\n",
      "[EPOCH LOSS 6701] loss: 1.5441\n",
      "[EPOCH LOSS 6801] loss: 1.8579\n",
      "[EPOCH LOSS 6901] loss: 2.9695\n",
      "[EPOCH LOSS 7001] loss: 1.4536\n",
      "[EPOCH RMSD 7001] loss: 154.7760\n",
      "[EPOCH LOSS 7101] loss: 1.6432\n",
      "[EPOCH LOSS 7201] loss: 1.4387\n",
      "[EPOCH LOSS 7301] loss: 16.0194\n",
      "[EPOCH LOSS 7401] loss: 1.3994\n",
      "[EPOCH LOSS 7501] loss: 1.5625\n",
      "[EPOCH LOSS 7601] loss: 1.9644\n",
      "[EPOCH LOSS 7701] loss: 1.5269\n",
      "[EPOCH LOSS 7801] loss: 1.6185\n",
      "[EPOCH LOSS 7901] loss: 1.5680\n",
      "[EPOCH LOSS 8001] loss: 1.5599\n",
      "[EPOCH RMSD 8001] loss: 152.2614\n",
      "[EPOCH LOSS 8101] loss: 1.3340\n",
      "[EPOCH LOSS 8201] loss: 3.0822\n",
      "[EPOCH LOSS 8301] loss: 1.5834\n",
      "[EPOCH LOSS 8401] loss: 1.4133\n",
      "[EPOCH LOSS 8501] loss: 35.2476\n",
      "[EPOCH LOSS 8601] loss: 2.0213\n",
      "[EPOCH LOSS 8701] loss: 1.4037\n",
      "[EPOCH LOSS 8801] loss: 1.4228\n",
      "[EPOCH LOSS 8901] loss: 5.2157\n",
      "[EPOCH LOSS 9001] loss: 15.8521\n",
      "[EPOCH RMSD 9001] loss: 112.6714\n",
      "[EPOCH LOSS 9101] loss: 1.6076\n",
      "[EPOCH LOSS 9201] loss: 1.5176\n",
      "[EPOCH LOSS 9301] loss: 1.4592\n",
      "[EPOCH LOSS 9401] loss: 1.7897\n",
      "[EPOCH LOSS 9501] loss: 1.3460\n",
      "[EPOCH LOSS 9601] loss: 1.5751\n",
      "[EPOCH LOSS 9701] loss: 1.8858\n",
      "[EPOCH LOSS 9801] loss: 1.5922\n",
      "[EPOCH LOSS 9901] loss: 1.5185\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import sys\n",
    "import resource\n",
    "import copy\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from data_classes import *\n",
    "from read_input import *\n",
    "from read_trainset import *\n",
    "from network import *\n",
    "from prepare_batches import *\n",
    "from traininit import *\n",
    "from data_set import *\n",
    "from data_loader import *\n",
    "from optimization_step import *\n",
    "from output_nn import *\n",
    "from py_aeio import *\n",
    "from bnn import BayesianNeuralNetwork\n",
    "from bnn import get_batch\n",
    "\n",
    "device = \"cpu\"\n",
    "tin_file = \"train.in\"\n",
    "tin = read_train_in(tin_file)\n",
    "torch.manual_seed(3)\n",
    "np.random.seed(tin.numpy_seed)\n",
    "tin.train_forces = False\n",
    "\n",
    "tin.train_file = 'Cu.active_learning'\n",
    "list_structures_energy, _, list_removed, max_nnb, tin = read_list_structures(tin)\n",
    "\n",
    "net = NetAtom(tin.networks_param[\"input_size\"], tin.networks_param[\"hidden_size\"],\n",
    "\t\t\t    tin.sys_species, tin.networks_param[\"activations\"], tin.alpha, device)\n",
    "\n",
    "bnn = BayesianNeuralNetwork(net)\n",
    "\n",
    "np.random.seed(42)\n",
    "dataset_size = len(list_structures_energy)\n",
    "indices = list(range(dataset_size))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "training_indices = indices[:5000]\n",
    "test_indices = indices[5000:6000]\n",
    "valid_indices = indices[6000:]\n",
    "\n",
    "training_structures_energy = [list_structures_energy[x] for x in training_indices]\n",
    "test_structures_energy     = [list_structures_energy[x] for x in test_indices]\n",
    "valid_structure_energy     = [list_structures_energy[x] for x in valid_indices]\n",
    "\n",
    "training_batch = get_batch(tin, training_structures_energy, max_nnb)\n",
    "test_batch     = get_batch(tin, test_structures_energy, max_nnb)\n",
    "valid_batch    = get_batch(tin, valid_structure_energy, max_nnb)\n",
    "\n",
    "EPOCHS = 10000\n",
    "NUM_SAMPLES = 10000\n",
    "LR = 0.01\n",
    "\n",
    "bnn.train(training_batch, EPOCHS, initial_lr=LR, verbose=True)\n",
    "\n",
    "valid_pred = bnn.predict(valid_batch,num_samples=NUM_SAMPLES)\n",
    "std_valid_batch = torch.std(valid_pred['obs'],0)\n",
    "\n",
    "test_pred = bnn.predict(test_batch,num_samples=NUM_SAMPLES)\n",
    "std_test_batch = torch.std(test_pred['obs'],0)\n",
    "idx_test_sorted = np.argsort(std_test_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSD valid set pre train 73.70998508396451\n",
      "STD valid set before training: 2.9060710028649224\n",
      "\n",
      "Training with 10 datapoints of std 2.272781467712229\n",
      "RMSD after training: 55.88661375316724\n",
      "STD valid set after training: 2.512414081468009\n",
      "\n",
      "Training with 10 datapoints of std 2.434894878076799\n",
      "RMSD after training: 56.19159301982575\n",
      "STD valid set after training: 2.4968948035325145\n",
      "\n",
      "Training with 10 datapoints of std 2.6256434976881464\n",
      "RMSD after training: 66.42992809616236\n",
      "STD valid set after training: 2.79984864442066\n",
      "\n",
      "Training with 10 datapoints of std 2.757753295772476\n",
      "RMSD after training: 33.702417532399984\n",
      "STD valid set after training: 1.9198488944367949\n",
      "\n",
      "Training with 10 datapoints of std 2.820945679456239\n",
      "RMSD after training: 65.49171845910185\n",
      "STD valid set after training: 2.7846856093749803\n",
      "\n",
      "Training with 10 datapoints of std 2.8764563980774716\n",
      "RMSD after training: 52.364929478276636\n",
      "STD valid set after training: 2.199613750124623\n",
      "\n",
      "Training with 10 datapoints of std 2.9604755382437045\n",
      "RMSD after training: 63.64756424959726\n",
      "STD valid set after training: 2.6907627019933664\n",
      "\n",
      "Training with 10 datapoints of std 3.2030453342060667\n",
      "RMSD after training: 35.801870540723414\n",
      "STD valid set after training: 1.9898622715605463\n",
      "\n",
      "Training with 10 datapoints of std 3.338911284195607\n",
      "RMSD after training: 36.76164227810738\n",
      "STD valid set after training: 2.2475597224610393\n",
      "\n",
      "Training with 10 datapoints of std 3.4315037733593443\n",
      "RMSD after training: 39.82934440289046\n",
      "STD valid set after training: 2.112664383374675\n"
     ]
    }
   ],
   "source": [
    "l2 = bnn.get_loss_RMSE(valid_batch, num_samples=NUM_SAMPLES)\n",
    "\n",
    "print('RMSD valid set pre train {}'.format(l2[0].item()))\n",
    "print('STD valid set before training: {}'.format(torch.mean(std_valid_batch).item()))\n",
    "print('STD test set before training: {}'.format(torch.mean(std_test_batch).item()))\n",
    "\n",
    "with open('std_test_multi_testalso.txt', 'w') as out:\n",
    "    out.write('RMSD valid set pre train {}\\n'.format(l2[0].item()))\n",
    "    out.write('STD valid set before training: {}\\n'.format(torch.mean(std_valid_batch).item()))\n",
    "    out.write('STD test set before training: {}\\n'.format(torch.mean(std_test_batch).item()))\n",
    "\n",
    "    for i in range(0, 10): \n",
    "        \n",
    "        l = list(range(i*100,i*100+10))\n",
    "\n",
    "        indices = [test_indices[x] for x in idx_test_sorted[l]]\n",
    "        std_new_points = [std_test_batch[x] for x in idx_test_sorted[l]]\n",
    "        print('\\nTraining with {} datapoints of std {}'.format(len(indices), np.array(std_new_points).mean()))\n",
    "        out.write('\\nTraining with {} datapoints of std {}\\n'.format(len(indices), np.array(std_new_points).mean()))\n",
    "\n",
    "        new_structure_energy = [list_structures_energy[x] for x in indices]\n",
    "        new_training_structures_energy = training_structures_energy + new_structure_energy\n",
    "        new_training_batch = get_batch(tin, new_training_structures_energy, max_nnb)\n",
    "\n",
    "        bnn1 = copy.deepcopy(bnn)\n",
    "        bnn1.train(new_training_batch, EPOCHS, initial_lr=LR, verbose=False)\n",
    "\n",
    "        valid_pred = bnn1.predict(valid_batch,num_samples=NUM_SAMPLES)\n",
    "        std_valid_batch = torch.mean(torch.std(valid_pred['obs'],0))\n",
    "        l2 = bnn1.get_loss_RMSE(valid_batch, num_samples=NUM_SAMPLES)\n",
    "    \n",
    "        print('RMSD after training: {}'.format(l2[0].item()))\n",
    "        out.write('RMSD after training: {}\\n'.format(l2[0].item()))\n",
    "\n",
    "        print('STD valid set after training: {}'.format(std_valid_batch.item()))\n",
    "        out.write('STD valid set after training: {}\\n'.format(std_valid_batch.item()))\n",
    "\n",
    "        test_pred = bnn1.predict(test_batch,num_samples=NUM_SAMPLES)\n",
    "        std_test_batch = torch.mean(torch.std(test_pred['obs'],0))\n",
    "\n",
    "        print('STD test set after training: {}'.format(std_test_batch.item()))\n",
    "        out.write('STD test set after training: {}\\n'.format(std_test_batch.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m l2_valid \u001b[39m=\u001b[39m bnn\u001b[39m.\u001b[39mget_loss_RMSE(valid_batch, num_samples\u001b[39m=\u001b[39mNUM_SAMPLES)\n\u001b[1;32m      2\u001b[0m l2_test \u001b[39m=\u001b[39m bnn\u001b[39m.\u001b[39mget_loss_RMSE(test_batch, num_samples\u001b[39m=\u001b[39mNUM_SAMPLES)\n\u001b[0;32m----> 4\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mRMSD valid set pre train \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(l2[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mitem()))\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mRMSD test set pre train \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(l2[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mitem()))\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mSTD valid set before training: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(torch\u001b[39m.\u001b[39mmean(std_valid_batch)\u001b[39m.\u001b[39mitem()))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'l2' is not defined"
     ]
    }
   ],
   "source": [
    "l2_valid = bnn.get_loss_RMSE(valid_batch, num_samples=NUM_SAMPLES)\n",
    "l2_test = bnn.get_loss_RMSE(test_batch, num_samples=NUM_SAMPLES)\n",
    "\n",
    "print('RMSD valid set pre train {}'.format(l2[0].item()))\n",
    "print('RMSD test set pre train {}'.format(l2[0].item()))\n",
    "\n",
    "print('STD valid set before training: {}'.format(torch.mean(std_valid_batch).item()))\n",
    "print('STD test set before training: {}'.format(torch.mean(std_test_batch).item()))\n",
    "\n",
    "with open('std_test_multi_testalso.txt', 'w') as out:\n",
    "    out.write('RMSD valid set pre train {}\\n'.format(l2_valid[0].item()))\n",
    "    out.write('RMSD test set pre train {}\\n'.format(l2_test[0].item()))\n",
    "    out.write('STD valid set before training: {}\\n'.format(torch.mean(std_valid_batch).item()))\n",
    "    out.write('STD test set before training: {}\\n'.format(torch.mean(std_test_batch).item()))\n",
    "\n",
    "    for i in range(0, 10): \n",
    "        \n",
    "        l = list(range(i*100,i*100+10))\n",
    "\n",
    "        indices = [test_indices[x] for x in idx_test_sorted[l]]\n",
    "        std_new_points = [std_test_batch[x] for x in idx_test_sorted[l]]\n",
    "        print('\\nTraining with {} datapoints of std {}'.format(len(indices), np.array(std_new_points).mean()))\n",
    "        out.write('\\nTraining with {} datapoints of std {}\\n'.format(len(indices), np.array(std_new_points).mean()))\n",
    "\n",
    "        new_structure_energy = [list_structures_energy[x] for x in indices]\n",
    "        new_training_structures_energy = training_structures_energy + new_structure_energy\n",
    "        new_training_batch = get_batch(tin, new_training_structures_energy, max_nnb)\n",
    "\n",
    "        bnn1 = copy.deepcopy(bnn)\n",
    "        bnn1.train(new_training_batch, EPOCHS, initial_lr=LR, verbose=False)\n",
    "\n",
    "        valid_pred = bnn1.predict(valid_batch,num_samples=NUM_SAMPLES)\n",
    "        std_valid_batch = torch.mean(torch.std(valid_pred['obs'],0))\n",
    "        l2 = bnn1.get_loss_RMSE(valid_batch, num_samples=NUM_SAMPLES)\n",
    "    \n",
    "        print('RMSD valid after training: {}'.format(l2[0].item()))\n",
    "        out.write('RMSD valid after training: {}\\n'.format(l2[0].item()))\n",
    "\n",
    "        print('STD valid set after training: {}'.format(std_valid_batch.item()))\n",
    "        out.write('STD valid set after training: {}\\n'.format(std_valid_batch.item()))\n",
    "\n",
    "        test_pred = bnn1.predict(test_batch,num_samples=NUM_SAMPLES)\n",
    "        new_std_test_batch = torch.mean(torch.std(test_pred['obs'],0))\n",
    "        l2_test = bnn1.get_loss_RMSE(test_batch, num_samples=NUM_SAMPLES)\n",
    "\n",
    "        print('RMSD test after training: {}'.format(l2_test[0].item()))\n",
    "        out.write('RMSD test after training: {}\\n'.format(l2_test[0].item()))\n",
    "\n",
    "        print('STD test set after training: {}'.format(new_std_test_batch.item()))\n",
    "        out.write('STD test set after training: {}\\n'.format(new_std_test_batch.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tyxe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
