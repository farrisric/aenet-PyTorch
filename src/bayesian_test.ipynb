{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nethome/farri002/miniconda3/envs/tyxe/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import sys\n",
    "import resource\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from data_classes import *\n",
    "from read_input import *\n",
    "from read_trainset import *\n",
    "from network import *\n",
    "from prepare_batches import *\n",
    "from traininit import *\n",
    "from data_set import *\n",
    "from data_loader import *\n",
    "from optimization_step import *\n",
    "from output_nn import *\n",
    "from py_aeio import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tin_file = \"/nethome/farri002/mlp-pt-au-o-h/ml-construction/PdO/desc-20-8/NN-20-20/train.in\"\n",
    "tin = read_train_in(tin_file)\n",
    "torch.manual_seed(tin.pytorch_seed)\n",
    "np.random.seed(tin.numpy_seed)\n",
    "if tin.verbose: io_input_reading(tin)\n",
    "tin.train_file = '/nethome/farri002/mlp-pt-au-o-h/ml-construction/PdO/desc-20-8/data.train.ascii'\n",
    "tin.train_forces_file = '/nethome/farri002/mlp-pt-au-o-h/ml-construction/PdO/desc-20-8/data.train.forces'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tin.verbose : io_trainingset_information()\n",
    "list_structures_energy, list_structures_forces, list_removed, max_nnb, tin = read_list_structures(tin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_removed = len(list_removed)\n",
    "N_struc_E = len(list_structures_energy)\n",
    "N_struc_F = len(list_structures_forces)\n",
    "if tin.verbose : io_trainingset_information_done(tin, tin.trainset_params, N_struc_E, N_struc_F, N_removed)\n",
    "\n",
    "if tin.verbose : io_prepare_batches()\n",
    "\n",
    "N_batch_train, N_batch_valid = select_batch_size(tin, list_structures_energy, list_structures_forces)\n",
    "\n",
    "# Join datasets with forces and only energies in a single torch dataset AND prepare batches\n",
    "train_forces_data, valid_forces_data, train_energy_data, valid_energy_data = select_batches(tin, tin.trainset_params, device, list_structures_energy, list_structures_forces,\n",
    "                                                                                        max_nnb, N_batch_train, N_batch_valid)\n",
    "\n",
    "del list_structures_energy\n",
    "del list_structures_forces\n",
    "\n",
    "if tin.verbose : io_prepare_batches_done(tin, train_energy_data, train_forces_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_train_data = GroupedDataset(train_energy_data, train_forces_data,\n",
    "\t\t\t\t\t\t\t\t\t memory_mode=tin.memory_mode, device=device, dataname=\"train\")\n",
    "grouped_valid_data = GroupedDataset(valid_energy_data, valid_forces_data,\n",
    "\t\t\t\t\t\t\t\t\t memory_mode=tin.memory_mode, device=device, dataname=\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_forces_data\n",
    "del valid_forces_data\n",
    "del train_energy_data\n",
    "del valid_energy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Initialize dataloader\n",
    "grouped_train_loader = DataLoader(grouped_train_data, batch_size=1, shuffle=False,\n",
    "                                  collate_fn=custom_collate, num_workers=0)\n",
    "grouped_valid_loader = DataLoader(grouped_valid_data, batch_size=1, shuffle=False,\n",
    "                                  collate_fn=custom_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesian_network import BayesianNetAtoms\n",
    "from pyro.nn.module import to_pyro_module_\n",
    "from pyro.nn import PyroSample\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "import pyro\n",
    "\n",
    "model = NetAtom(tin.networks_param[\"input_size\"], tin.networks_param[\"hidden_size\"],\n",
    "\t\t\t    tin.sys_species, tin.networks_param[\"activations\"], tin.alpha, device)\n",
    "\n",
    "to_pyro_module_(model)\n",
    "\n",
    "weight_labels = [f'Pt_h{i}_weight' for i in range(3)] + [f'O_h{i}_weight' for i in range(3)]\n",
    "bias_labels = [f'Pt_h{i}_bias' for i in range(3)] + [f'O_h{i}_bias' for i in range(3)]\n",
    "\n",
    "i = 0\n",
    "for m in model.modules():\n",
    "    for name, value in list(m.named_parameters(recurse=False)):\n",
    "        if name == 'weight':\n",
    "            setattr(m, name, PyroSample(prior=dist.Normal(0, 1)\n",
    "                                              .expand(value.shape)\n",
    "                                              .to_event(value.dim())))\n",
    "        if name == 'bias':\n",
    "            setattr(m, name, PyroSample(prior=dist.Normal(0, 10)\n",
    "                                              .expand(value.shape)\n",
    "                                              .to_event(value.dim())))\n",
    "            i += 1\n",
    "\n",
    "def bayesian_net(grp_descrp, logic_reduce, grp_energy=None):\n",
    "    \n",
    "    local_plates = {i : pyro.plate(f'iest_{i}', len(grp_descrp[i])) for i in range(len(model.species))}\n",
    "    local_sigma = {iesp : pyro.sample(f'noise_{iesp}', dist.Uniform(0,10)) for iesp in range(len(model.species))}\n",
    "    sigma_fin = pyro.sample('noise', dist.Uniform(0,10))\n",
    "\n",
    "    partial_E_ann = [0 for i in range(len(model.species))]\n",
    "\n",
    "    for iesp, local_plate in local_plates.items():\n",
    "        partial_E_ann[iesp] = model.functions[iesp](grp_descrp[iesp])\n",
    "\n",
    "    list_E_ann = torch.zeros( (len(logic_reduce[0])), device=model.device ).double()\n",
    "    for iesp in range(len(model.species)):\n",
    "        list_E_ann = list_E_ann + torch.einsum( \"ij,ki->k\", partial_E_ann[iesp], logic_reduce[iesp])\n",
    "\n",
    "    with pyro.plate('data', size = len(logic_reduce[0])):#, subsample_size= 128) as ind: # number of configurations\n",
    "        a = pyro.sample('obs', dist.Normal(list_E_ann, sigma_fin), obs=grp_energy)\n",
    "         #obs=grp_energy.index_select(0, ind))\n",
    "        \n",
    "    return list_E_ann\n",
    "      \n",
    "def bnn(grp_descrp, logic_reduce, grp_energy=None):    \n",
    "    partial_E_ann = [0 for i in range(len(model.species))]\n",
    "        \n",
    "    for iesp in range(len(model.species)):\n",
    "        partial_E_ann[iesp] = model.functions[iesp](grp_descrp[iesp])\n",
    "\n",
    "    # Gather back all atoms corresponding to the same strucuture from partial_E_ann\n",
    "    \n",
    "    sigma = pyro.sample('noise', dist.Uniform(0,10))\n",
    "    with pyro.plate('data', len(logic_reduce[0])):\n",
    "\n",
    "        list_E_ann = torch.zeros( (len(logic_reduce[0])), device=model.device ).double()\n",
    "        for iesp in range(len(model.species)):\n",
    "            list_E_ann = list_E_ann + torch.einsum( \"ij,ki->k\", partial_E_ann[iesp], logic_reduce[iesp] )\n",
    "        pyro.sample('obs', dist.Normal(list_E_ann, sigma), obs=grp_energy)\n",
    "    return list_E_ann\n",
    "\n",
    "# model = BayesianNetAtoms(net)       \n",
    "guide = AutoDiagonalNormal(bayesian_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(grouped_train_loader):\n",
    "    for data_batch in grouped_train_loader:\n",
    "        grp_descrp, grp_energy, logic_reduce = data_batch[0][10], data_batch[0][11], data_batch[0][12]\n",
    "\n",
    "    grp_descrp[0] = grp_descrp[0].float()\n",
    "    grp_descrp[1] = grp_descrp[1].float()\n",
    "\n",
    "    logic_reduce[0] = logic_reduce[0].float()\n",
    "    logic_reduce[1] = logic_reduce[1].float()\n",
    "\n",
    "    return grp_descrp, grp_energy, logic_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer import SVI, Trace_ELBO\n",
    "\n",
    "grp_descrp, grp_energy, logic_reduce = get_train_test(grouped_train_loader)\n",
    "pyro.clear_param_store()\n",
    "adam = pyro.optim.Adam({\"lr\": 0.05})\n",
    "svi = SVI(bayesian_net, guide, adam, loss=Trace_ELBO())\n",
    "elbos = []\n",
    "for x in range(20000):\n",
    "    elbos.append(svi.step(grp_descrp, logic_reduce, grp_energy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_descrp, grp_energy, logic_reduce = get_train_test(grouped_valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyro.infer import Predictive\n",
    "\n",
    "def summary(samples):\n",
    "    site_stats = {}\n",
    "    for k, v in samples.items():\n",
    "        site_stats[k] = {\n",
    "            \"mean\": torch.mean(v, 0).numpy(),\n",
    "            \"std\": torch.std(v, 0).numpy(),\n",
    "            \"5%\": v.kthvalue(int(len(v) * 0.05), dim=0)[0].numpy(),\n",
    "            \"95%\": v.kthvalue(int(len(v) * 0.95), dim=0)[0].numpy(),\n",
    "        }\n",
    "    return site_stats\n",
    "\n",
    "\n",
    "predictive = Predictive(bnn, guide=guide, num_samples=800,\n",
    "                        return_sites=(\"weight\", \"obs\", \"_RETURN\"))\n",
    "\n",
    "samples = predictive(grp_descrp, logic_reduce)\n",
    "pred_summary = summary(samples)\n",
    "mu = pred_summary[\"_RETURN\"]\n",
    "y = pred_summary[\"obs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-38.0, -31.5)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "i = 0\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,8))\n",
    "x = np.linspace(-100,100,1000)\n",
    "ax.plot(x,x, '--r')\n",
    "for y_pred, y_std, y in zip(mu['mean'], mu['std'], grp_energy):\n",
    "    #plt.scatter(y, y_pred, color='b')\n",
    "    ax.errorbar(y, y_pred,fmt='o', c='blue', yerr=y_std)\n",
    "    #ax[1].errorbar(y_pred, y,fmt='o', c='red', xerr=y_std)\n",
    "    i += 1\n",
    "\n",
    "    if i == 50:\n",
    "        break\n",
    "\n",
    "ax.set_ylim(-38,-31.5)\n",
    "ax.set_xlim(-38,-31.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_descrp, grp_energy, logic_reduce = get_train_test(grouped_valid_loader)\n",
    "for x in range(10000):\n",
    "    elbos.append(svi.step(grp_descrp, logic_reduce, grp_energy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = predictive(grp_descrp, logic_reduce)\n",
    "pred_summary = summary(samples)\n",
    "mu = pred_summary[\"_RETURN\"]\n",
    "y = pred_summary[\"obs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-38.0, -31.5)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,8))\n",
    "x = np.linspace(-100,100,1000)\n",
    "ax.plot(x,x, '--r')\n",
    "for y_pred, y_std, y in zip(mu['mean'], mu['std'], grp_energy):\n",
    "    #plt.scatter(y, y_pred, color='b')\n",
    "    ax.errorbar(y, y_pred,fmt='o', c='blue', yerr=y_std)\n",
    "    #ax[1].errorbar(y_pred, y,fmt='o', c='red', xerr=y_std)\n",
    "    i += 1\n",
    "\n",
    "    if i == 50:\n",
    "        break\n",
    "\n",
    "ax.set_ylim(-38,-31.5)\n",
    "ax.set_xlim(-38,-31.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-32.17991134122014, 0.9080880242909194, tensor(-35.2630, dtype=torch.float64))\n",
      "(-31.29842812769115, 1.485673051534721, tensor(-33.0803, dtype=torch.float64))\n",
      "(-31.095640621185304, 0.8518847069499551, tensor(-32.9987, dtype=torch.float64))\n",
      "(-31.062216258049013, 0.7589689505429384, tensor(-32.7180, dtype=torch.float64))\n",
      "(-30.883537215981633, 1.4282776824737098, tensor(-32.8367, dtype=torch.float64))\n",
      "(-32.74475765556097, 1.1331190348227982, tensor(-34.4349, dtype=torch.float64))\n",
      "(-32.706314021199944, 1.1345337872560601, tensor(-34.9522, dtype=torch.float64))\n",
      "(-32.69975954176858, 1.1484318981263002, tensor(-34.4518, dtype=torch.float64))\n",
      "(-32.40832112625241, 1.1883306539145915, tensor(-34.0074, dtype=torch.float64))\n",
      "(-32.74712166847661, 1.0607945956014524, tensor(-34.6884, dtype=torch.float64))\n",
      "(-32.74387921022251, 1.0921743300244635, tensor(-35.7366, dtype=torch.float64))\n",
      "(-32.8728396467492, 1.1343946655029045, tensor(-36.2166, dtype=torch.float64))\n",
      "(-32.75923109678551, 1.6169213307575687, tensor(-35.3710, dtype=torch.float64))\n",
      "(-34.6316984112002, 2.066477733733938, tensor(-36.4493, dtype=torch.float64))\n",
      "(-32.01694433987141, 1.2192786832545643, tensor(-33.9183, dtype=torch.float64))\n",
      "(-32.82579474544153, 1.190009734694192, tensor(-34.6654, dtype=torch.float64))\n",
      "(-28.505525208339094, 4.519698412095607, tensor(-32.9166, dtype=torch.float64))\n",
      "(-31.393212018515914, 0.7968619137805528, tensor(-33.4529, dtype=torch.float64))\n",
      "(-32.869987414442, 1.134382478119259, tensor(-36.2139, dtype=torch.float64))\n",
      "(-32.18783856675029, 0.9636791180661907, tensor(-35.1934, dtype=torch.float64))\n",
      "(-32.68539917992428, 1.1231234521474323, tensor(-34.8216, dtype=torch.float64))\n",
      "(-31.490691875759513, 0.8025084870897823, tensor(-33.9083, dtype=torch.float64))\n",
      "(-32.7741292287223, 1.1037910697537423, tensor(-33.9785, dtype=torch.float64))\n",
      "(-32.75159683519974, 1.0926505144294025, tensor(-34.3598, dtype=torch.float64))\n",
      "(-30.504701145105063, 2.9830193862313004, tensor(-33.3216, dtype=torch.float64))\n",
      "(-31.087017430774868, 1.4633688896947874, tensor(-33.3168, dtype=torch.float64))\n",
      "(-32.76565568448976, 1.0710012413167864, tensor(-34.7565, dtype=torch.float64))\n",
      "(-32.387012907546016, 1.1277273886548522, tensor(-34.9970, dtype=torch.float64))\n",
      "(-32.835177969504144, 1.0842041741208965, tensor(-35.6766, dtype=torch.float64))\n",
      "(-32.32471861891449, 1.8187177791262237, tensor(-34.0428, dtype=torch.float64))\n",
      "(-32.54126877980307, 1.0247476989235196, tensor(-35.5642, dtype=torch.float64))\n",
      "(-31.059139249324797, 0.7293595008701172, tensor(-32.7478, dtype=torch.float64))\n",
      "(-32.7661913000606, 1.1669283591318222, tensor(-33.9921, dtype=torch.float64))\n",
      "(-32.91335682829842, 1.1637696039174046, tensor(-36.2620, dtype=torch.float64))\n",
      "(-32.78075243981555, 1.0494483994471149, tensor(-34.6657, dtype=torch.float64))\n",
      "(-31.102666912078856, 0.8684718975364154, tensor(-33.0844, dtype=torch.float64))\n",
      "(-32.86377127125859, 1.1452676091606169, tensor(-36.1490, dtype=torch.float64))\n",
      "(-32.45121565273032, 1.066169226282173, tensor(-35.3363, dtype=torch.float64))\n",
      "(-32.71734955776483, 1.1143570338049216, tensor(-34.9256, dtype=torch.float64))\n",
      "(-31.465862377714366, 0.8209446159739554, tensor(-33.7312, dtype=torch.float64))\n",
      "(-32.187070592306554, 0.9717305050220675, tensor(-35.1903, dtype=torch.float64))\n",
      "(-32.80203554365784, 1.1000277202956303, tensor(-35.9812, dtype=torch.float64))\n",
      "(-33.343817002307624, 1.4009400107446606, tensor(-36.6009, dtype=torch.float64))\n",
      "(-31.461958299372345, 0.8132317724790388, tensor(-33.8236, dtype=torch.float64))\n",
      "(-32.87564121801406, 1.0958466687686255, tensor(-33.4714, dtype=torch.float64))\n",
      "(-32.685317139904946, 1.244797856131689, tensor(-33.5472, dtype=torch.float64))\n",
      "(-32.80117877718061, 1.0491684678539324, tensor(-35.6035, dtype=torch.float64))\n",
      "(-32.7953486668691, 1.069221023803951, tensor(-35.6427, dtype=torch.float64))\n",
      "(-33.76009553294629, 1.9186955100529963, tensor(-36.3568, dtype=torch.float64))\n",
      "(-32.81942548615858, 1.0871139593756738, tensor(-35.1616, dtype=torch.float64))\n",
      "(-32.849340814035386, 1.1085894718458855, tensor(-33.0273, dtype=torch.float64))\n",
      "(-32.81103169845417, 1.2040078673901509, tensor(-35.8483, dtype=torch.float64))\n",
      "(-32.69622638132423, 1.1426981682821002, tensor(-34.3698, dtype=torch.float64))\n",
      "(-33.32589970808476, 1.3925938540513856, tensor(-36.5544, dtype=torch.float64))\n",
      "(-33.009756837412716, 2.045395999703601, tensor(-34.9449, dtype=torch.float64))\n",
      "(-32.760577583499256, 1.0991288133893498, tensor(-34.8655, dtype=torch.float64))\n",
      "(-31.99862546335906, 0.9252500281245107, tensor(-34.4042, dtype=torch.float64))\n",
      "(-33.345959032475946, 1.4063217155876733, tensor(-36.6134, dtype=torch.float64))\n",
      "(-31.843517593964933, 0.8320967059645356, tensor(-34.5255, dtype=torch.float64))\n",
      "(-31.13602863073349, 0.8830516893601281, tensor(-33.1229, dtype=torch.float64))\n",
      "(-31.85277409862727, 0.8219667501027411, tensor(-34.6328, dtype=torch.float64))\n",
      "(-28.323371275346727, 3.768621176388557, tensor(-31.4629, dtype=torch.float64))\n",
      "(-32.78054108222946, 1.0726618424383882, tensor(-34.5889, dtype=torch.float64))\n",
      "(-33.29709891185164, 1.52688454459606, tensor(-36.6030, dtype=torch.float64))\n",
      "(-32.74053019095212, 1.0908494056090592, tensor(-34.2948, dtype=torch.float64))\n",
      "(-32.746213162522764, 1.1151012062464223, tensor(-35.7260, dtype=torch.float64))\n",
      "(-32.74212305620313, 1.1144510911229388, tensor(-35.0782, dtype=torch.float64))\n",
      "(-32.78844185931608, 1.1535657824658663, tensor(-35.6979, dtype=torch.float64))\n",
      "(-0.6305942003056407, 0.4884328451301074, tensor(-0.3190, dtype=torch.float64))\n",
      "(-31.369120962079613, 0.8486799673495952, tensor(-33.3806, dtype=torch.float64))\n",
      "(-32.57687440194189, 1.5402040789623725, tensor(-34.2976, dtype=torch.float64))\n",
      "(-32.71525202771649, 1.1887961683205164, tensor(-34.3361, dtype=torch.float64))\n",
      "(-31.8205231551826, 0.7911553591247709, tensor(-34.6205, dtype=torch.float64))\n",
      "(-31.042877838611602, 0.7802703322753497, tensor(-32.5829, dtype=torch.float64))\n",
      "(-29.329453969988972, 3.2761758011779065, tensor(-32.9336, dtype=torch.float64))\n",
      "(-32.79506548900157, 1.128397279836649, tensor(-34.5333, dtype=torch.float64))\n",
      "(-31.091766805648803, 0.7255968477233504, tensor(-32.8834, dtype=torch.float64))\n",
      "(-31.433656134102492, 0.8352620526685138, tensor(-33.6813, dtype=torch.float64))\n",
      "(-32.865810107253495, 1.1945400069234156, tensor(-33.3402, dtype=torch.float64))\n",
      "(-33.25909615203738, 1.343778409350851, tensor(-36.3873, dtype=torch.float64))\n",
      "(-34.68993630487472, 2.3503449612321936, tensor(-37.0531, dtype=torch.float64))\n",
      "(-30.58582834482193, 1.5542775527114523, tensor(-32.2292, dtype=torch.float64))\n",
      "(-32.83969466991723, 1.170048333496618, tensor(-36.1604, dtype=torch.float64))\n",
      "(-32.724191460181025, 1.1390840777456717, tensor(-32.9914, dtype=torch.float64))\n",
      "(-32.848156357370314, 1.2139759536247257, tensor(-36.1685, dtype=torch.float64))\n",
      "(-32.68465821262449, 1.149197627552068, tensor(-34.3832, dtype=torch.float64))\n",
      "(-32.740194235462695, 1.0966274715920272, tensor(-34.2654, dtype=torch.float64))\n",
      "(-33.32368323089555, 1.5628049291193993, tensor(-36.6014, dtype=torch.float64))\n",
      "(-32.77756527984515, 1.1063896010942043, tensor(-35.1861, dtype=torch.float64))\n",
      "(-32.51538894029334, 1.1285434427228387, tensor(-35.6242, dtype=torch.float64))\n",
      "(-32.84391637312248, 1.080118379941309, tensor(-35.8193, dtype=torch.float64))\n",
      "(-32.647385217454286, 1.1904570911298282, tensor(-34.4214, dtype=torch.float64))\n",
      "(-32.75607394527644, 1.1335214280757624, tensor(-34.3733, dtype=torch.float64))\n",
      "(-33.28466857753694, 1.5761823315082024, tensor(-36.2790, dtype=torch.float64))\n",
      "(-32.465021067801864, 1.454685356010524, tensor(-34.7734, dtype=torch.float64))\n",
      "(-32.715284174717965, 1.0689656993492915, tensor(-35.1861, dtype=torch.float64))\n",
      "(-31.84539128754288, 0.8317049530044711, tensor(-34.6093, dtype=torch.float64))\n",
      "(-31.72316583050415, 1.4756638544421599, tensor(-33.8002, dtype=torch.float64))\n",
      "(-32.727084992993625, 1.1832088793527653, tensor(-35.6452, dtype=torch.float64))\n",
      "(-32.671385427489874, 1.2288935026207506, tensor(-34.7319, dtype=torch.float64))\n",
      "(-31.135113623142242, 0.8061595633095593, tensor(-33.0973, dtype=torch.float64))\n",
      "(-32.817069065645335, 1.0498893931306241, tensor(-35.1939, dtype=torch.float64))\n",
      "(-3.4339955359697343, 0.16116936720714725, tensor(-3.6682, dtype=torch.float64))\n",
      "(-31.1154652428627, 0.853903811207042, tensor(-33.0925, dtype=torch.float64))\n",
      "(-31.457749543841928, 0.8549310079705548, tensor(-33.4699, dtype=torch.float64))\n",
      "(-32.8121216321364, 1.0558099418201772, tensor(-35.1359, dtype=torch.float64))\n",
      "(-32.39070681076497, 1.0790545293687996, tensor(-35.1230, dtype=torch.float64))\n",
      "(-0.5598720623925328, 0.6149304344354879, tensor(-0.7602, dtype=torch.float64))\n",
      "(-32.38280522681773, 1.0426217971429128, tensor(-34.4868, dtype=torch.float64))\n",
      "(-30.394617937803268, 2.654003471453023, tensor(-33.0329, dtype=torch.float64))\n",
      "(-32.50620428584516, 1.159611358478698, tensor(-35.7451, dtype=torch.float64))\n",
      "(-32.715268039405345, 1.1016367031256922, tensor(-34.4267, dtype=torch.float64))\n",
      "(-32.79314178163186, 1.1407729901214378, tensor(-35.6583, dtype=torch.float64))\n",
      "(-31.04341619491577, 0.8061638527069471, tensor(-32.7991, dtype=torch.float64))\n",
      "(-32.927375931032, 1.1632687323605175, tensor(-36.2471, dtype=torch.float64))\n",
      "(-31.089995815753937, 0.7589174394799225, tensor(-32.8036, dtype=torch.float64))\n",
      "(-31.068603296820076, 2.313111881345718, tensor(-32.8259, dtype=torch.float64))\n",
      "(-32.72168554490432, 1.1342392134052652, tensor(-34.9978, dtype=torch.float64))\n",
      "(-33.728076820056884, 1.6260561427830675, tensor(-36.9264, dtype=torch.float64))\n",
      "(-33.204120574854315, 1.6388509720506401, tensor(-36.3461, dtype=torch.float64))\n",
      "(-32.736836429964754, 1.061763160382576, tensor(-35.1659, dtype=torch.float64))\n",
      "(-32.73994969828054, 1.0781172962232517, tensor(-34.9457, dtype=torch.float64))\n",
      "(-31.171659952774643, 2.695084833735885, tensor(-34.0616, dtype=torch.float64))\n",
      "(-32.837024492975324, 1.1648207489832618, tensor(-34.7557, dtype=torch.float64))\n",
      "(-32.88350847737863, 1.1439864130824595, tensor(-36.2639, dtype=torch.float64))\n",
      "(-32.75390326477587, 1.1806394735647219, tensor(-35.0453, dtype=torch.float64))\n",
      "(-32.75809975609183, 1.0668881867557531, tensor(-34.2141, dtype=torch.float64))\n",
      "(-32.82485136758536, 1.1798003224081832, tensor(-34.8061, dtype=torch.float64))\n",
      "(-33.74202550591901, 1.4716794784457055, tensor(-36.9651, dtype=torch.float64))\n",
      "(-32.543735789470375, 1.0335290129178676, tensor(-35.8019, dtype=torch.float64))\n",
      "(-31.118114887177946, 1.5791168687960575, tensor(-33.3744, dtype=torch.float64))\n",
      "(-3.4576138252019883, 0.08381053222610432, tensor(-3.6746, dtype=torch.float64))\n",
      "(-0.7806049394235015, 0.13399791081676568, tensor(-0.6834, dtype=torch.float64))\n",
      "(-32.69133845791221, 1.1317409147443966, tensor(-34.3140, dtype=torch.float64))\n",
      "(-31.101795666217804, 0.7575128490590649, tensor(-32.9828, dtype=torch.float64))\n",
      "(-32.69916882520542, 1.2176507381360095, tensor(-34.9550, dtype=torch.float64))\n",
      "(-31.439092287439852, 1.6029931142780236, tensor(-33.4107, dtype=torch.float64))\n",
      "(-30.87705284833908, 1.0563187627533732, tensor(-32.2712, dtype=torch.float64))\n",
      "(-32.75341195216402, 1.1808708573141815, tensor(-33.9909, dtype=torch.float64))\n",
      "(-32.771725005544724, 1.1317254207148164, tensor(-34.8881, dtype=torch.float64))\n",
      "(-32.834445522129535, 1.182031547902006, tensor(-36.0345, dtype=torch.float64))\n",
      "(-32.532633919976654, 1.3982095829282937, tensor(-35.1180, dtype=torch.float64))\n",
      "(-33.736431984677914, 1.463624539027466, tensor(-36.9584, dtype=torch.float64))\n",
      "(-33.73036059185863, 1.624362315912553, tensor(-36.8924, dtype=torch.float64))\n",
      "(-31.42556402940303, 0.7779539493037175, tensor(-33.5075, dtype=torch.float64))\n",
      "(-32.53486734034494, 1.6524576995897446, tensor(-34.3402, dtype=torch.float64))\n",
      "(-31.45121454231441, 0.8936712025091315, tensor(-33.4884, dtype=torch.float64))\n",
      "(-32.176228593811395, 0.9004415769435485, tensor(-35.2526, dtype=torch.float64))\n",
      "(-25.549391800165175, 3.4735636974055204, tensor(-26.3898, dtype=torch.float64))\n",
      "(-32.68454877737909, 1.1645139058130003, tensor(-34.8252, dtype=torch.float64))\n",
      "(-32.71091255497188, 1.2496883511463819, tensor(-34.1463, dtype=torch.float64))\n",
      "(-33.5770385152474, 1.5606606943101267, tensor(-36.3303, dtype=torch.float64))\n",
      "(-31.14906763792038, 0.7559410397779516, tensor(-33.0324, dtype=torch.float64))\n",
      "(-32.72729228647426, 1.0608899858055154, tensor(-35.2848, dtype=torch.float64))\n",
      "(-32.09988816168159, 0.8673481583163888, tensor(-34.9453, dtype=torch.float64))\n",
      "(-31.142313449382783, 0.9729822396464616, tensor(-33.1785, dtype=torch.float64))\n",
      "(-33.30764033794403, 1.595773805693395, tensor(-36.6494, dtype=torch.float64))\n",
      "(-32.69054072806612, 1.1810045527470125, tensor(-34.7444, dtype=torch.float64))\n",
      "(-32.701961529683324, 1.1674272298613844, tensor(-34.7464, dtype=torch.float64))\n",
      "(-31.081892675254494, 1.9221594450625843, tensor(-33.9909, dtype=torch.float64))\n",
      "(-33.19397138029337, 1.5359802471756616, tensor(-36.5974, dtype=torch.float64))\n",
      "(-30.983822223115713, 1.1953455630216505, tensor(-32.9933, dtype=torch.float64))\n",
      "(-32.1719926692918, 0.987912250908981, tensor(-35.0630, dtype=torch.float64))\n",
      "(-33.17156072193757, 1.3111326894042021, tensor(-36.0515, dtype=torch.float64))\n",
      "(-32.75353063257411, 1.1261946022823635, tensor(-36.0037, dtype=torch.float64))\n",
      "(-32.45212837580591, 1.09807939976349, tensor(-34.3345, dtype=torch.float64))\n",
      "(-0.6312394649907946, 0.4886029039207585, tensor(-0.3038, dtype=torch.float64))\n",
      "(-32.769872278813274, 1.1385352527019834, tensor(-35.7494, dtype=torch.float64))\n",
      "(-32.19126806724817, 1.0121324384770503, tensor(-35.0379, dtype=torch.float64))\n",
      "(-32.72598154276609, 1.1078959974551816, tensor(-35.1535, dtype=torch.float64))\n",
      "(-32.79763155810535, 1.066845025481849, tensor(-35.6503, dtype=torch.float64))\n",
      "(-32.81019242649898, 1.0812374696039806, tensor(-35.9757, dtype=torch.float64))\n",
      "(-31.709916358701886, 0.9837458514627757, tensor(-33.7867, dtype=torch.float64))\n",
      "(-31.854689619615673, 0.7958714800981449, tensor(-34.6007, dtype=torch.float64))\n",
      "(-32.728840224444866, 1.0582666580685018, tensor(-35.0091, dtype=torch.float64))\n",
      "(-32.76368380336091, 1.161884496884356, tensor(-35.4857, dtype=torch.float64))\n",
      "(-32.18673059944064, 0.965740977182681, tensor(-35.1857, dtype=torch.float64))\n",
      "(-32.720604561921206, 1.1125401311292002, tensor(-35.0692, dtype=torch.float64))\n",
      "(-32.76965938411653, 1.113562279223827, tensor(-35.9525, dtype=torch.float64))\n",
      "(-33.906889289598915, 1.768754493284274, tensor(-36.1924, dtype=torch.float64))\n",
      "(-32.777597550489006, 1.031985004655133, tensor(-34.9028, dtype=torch.float64))\n",
      "(-32.2374364146404, 1.4029820383129974, tensor(-34.1703, dtype=torch.float64))\n",
      "(-31.44940427629277, 0.8567105482522201, tensor(-33.5190, dtype=torch.float64))\n",
      "(-32.553742449637504, 1.105938594285717, tensor(-35.5140, dtype=torch.float64))\n",
      "(-32.72934036839754, 1.172727510057738, tensor(-35.5688, dtype=torch.float64))\n",
      "(-32.749911989085376, 1.0896677544557318, tensor(-35.0284, dtype=torch.float64))\n",
      "(-31.37577482016757, 0.8271901554695944, tensor(-33.2354, dtype=torch.float64))\n",
      "(-32.79901054499671, 1.0856692677130384, tensor(-35.4188, dtype=torch.float64))\n",
      "(-32.749755497686564, 1.0555458821509365, tensor(-34.8393, dtype=torch.float64))\n",
      "(-32.2470540381968, 1.408123351151857, tensor(-34.1739, dtype=torch.float64))\n",
      "(-32.812994545158, 1.0811904160555423, tensor(-35.1143, dtype=torch.float64))\n",
      "(-32.72164673130959, 1.1372948924136832, tensor(-34.8863, dtype=torch.float64))\n",
      "(-31.44854682840407, 0.8575580813068283, tensor(-33.6591, dtype=torch.float64))\n",
      "(-32.732294245455414, 1.1838924083211084, tensor(-35.6434, dtype=torch.float64))\n",
      "(-30.055844192951916, 2.8995675875826614, tensor(-33.3064, dtype=torch.float64))\n",
      "(-32.38753595326096, 1.0706426510706406, tensor(-34.2980, dtype=torch.float64))\n",
      "(-31.01846930159256, 1.6288614132700485, tensor(-33.1341, dtype=torch.float64))\n",
      "(-31.312940084971487, 0.9287743646645732, tensor(-33.1098, dtype=torch.float64))\n",
      "(-31.13523771047592, 0.8056906214282213, tensor(-33.0785, dtype=torch.float64))\n",
      "(-33.3785621150583, 1.6379670601353062, tensor(-36.1561, dtype=torch.float64))\n",
      "(-31.758767278343438, 0.8383251623221536, tensor(-34.2838, dtype=torch.float64))\n",
      "(-32.067365835234526, 1.020693505852816, tensor(-34.5971, dtype=torch.float64))\n",
      "(-33.31435030389577, 1.5442064247283553, tensor(-36.6054, dtype=torch.float64))\n",
      "(-32.81617148915306, 1.1987714426257323, tensor(-34.3959, dtype=torch.float64))\n",
      "(-31.45775765227154, 0.8548109700683598, tensor(-33.4701, dtype=torch.float64))\n",
      "(-32.77348278077319, 1.181431030808603, tensor(-34.8481, dtype=torch.float64))\n",
      "(-31.508320982158185, 1.751292601165294, tensor(-33.6384, dtype=torch.float64))\n",
      "(-33.247454888336364, 1.3778205207065037, tensor(-36.5314, dtype=torch.float64))\n",
      "(-31.114532115459443, 0.7622495733464786, tensor(-33.0221, dtype=torch.float64))\n",
      "(-32.7799144170247, 1.1050883098901008, tensor(-34.5507, dtype=torch.float64))\n",
      "(-31.471445440500975, 0.8112171411037651, tensor(-33.8167, dtype=torch.float64))\n",
      "(-33.12416690837592, 1.446001533839087, tensor(-36.1925, dtype=torch.float64))\n",
      "(-31.12443069934845, 0.7643488722421236, tensor(-33.0518, dtype=torch.float64))\n",
      "(-0.6370586182177067, 0.4849391374702926, tensor(-0.1404, dtype=torch.float64))\n",
      "(-32.831192975975576, 1.1702838687478656, tensor(-35.9947, dtype=torch.float64))\n",
      "(-32.74600980855524, 1.0366958169438012, tensor(-34.8786, dtype=torch.float64))\n",
      "(-31.449073861334472, 0.8621888856581761, tensor(-33.5154, dtype=torch.float64))\n",
      "(-32.831423185970635, 1.1125001714698803, tensor(-33.5989, dtype=torch.float64))\n",
      "(-32.82343851581216, 1.0927330304667804, tensor(-35.2612, dtype=torch.float64))\n",
      "(-32.082693219129, 0.9199149862512792, tensor(-34.7649, dtype=torch.float64))\n",
      "(-32.75771746397018, 1.1538045057389852, tensor(-35.1497, dtype=torch.float64))\n",
      "(-32.758941591456534, 1.1320129280517663, tensor(-34.5688, dtype=torch.float64))\n",
      "(-31.453149470631033, 1.8322272367799328, tensor(-34.0346, dtype=torch.float64))\n",
      "(-31.82521071838215, 0.8267731449195619, tensor(-34.5586, dtype=torch.float64))\n",
      "(-32.703884957768025, 1.1015198596099458, tensor(-34.9764, dtype=torch.float64))\n",
      "(-32.769537954498084, 1.1219529113747744, tensor(-34.5134, dtype=torch.float64))\n",
      "(-31.756161146461963, 0.830692216126559, tensor(-34.3573, dtype=torch.float64))\n",
      "(-32.844891627300534, 1.1870922241414692, tensor(-36.1567, dtype=torch.float64))\n",
      "(-31.427253718208522, 0.7685939227433085, tensor(-33.6472, dtype=torch.float64))\n",
      "(-32.74593131789938, 1.1201170229341464, tensor(-35.9659, dtype=torch.float64))\n",
      "(-32.83234305197373, 1.0432111090980807, tensor(-34.6978, dtype=torch.float64))\n",
      "(-32.751050969380884, 1.1377304979735248, tensor(-35.7734, dtype=torch.float64))\n",
      "(-31.641158945262433, 2.5467376568654987, tensor(-33.5466, dtype=torch.float64))\n",
      "(-31.735047915913164, 0.916990072532161, tensor(-34.2049, dtype=torch.float64))\n",
      "(-33.30993866186589, 1.5775610401740767, tensor(-36.6311, dtype=torch.float64))\n",
      "(-32.783873184602704, 1.105853328663725, tensor(-35.8467, dtype=torch.float64))\n",
      "(-31.497162811663003, 0.7732256448656609, tensor(-33.9422, dtype=torch.float64))\n",
      "(-32.41194068053737, 1.4933294141769162, tensor(-34.6286, dtype=torch.float64))\n",
      "(-32.35372519917786, 1.0742250496969818, tensor(-33.9305, dtype=torch.float64))\n",
      "(-31.102739391326903, 0.7703082276987151, tensor(-32.9828, dtype=torch.float64))\n",
      "(-32.7323905386962, 1.0541879734398478, tensor(-34.7608, dtype=torch.float64))\n",
      "(-31.159798663463445, 1.0782937101429497, tensor(-32.9422, dtype=torch.float64))\n",
      "(-31.124799115657808, 0.7874623346899167, tensor(-33.0104, dtype=torch.float64))\n",
      "(-32.82122003952041, 1.1136461715816768, tensor(-34.6534, dtype=torch.float64))\n",
      "(-31.691808737609534, 1.5997109013416397, tensor(-33.1656, dtype=torch.float64))\n",
      "(-34.24748537139967, 1.9610578143575668, tensor(-36.9871, dtype=torch.float64))\n",
      "(-33.22387731352821, 1.3516446767288697, tensor(-36.3508, dtype=torch.float64))\n",
      "(-32.86014838160947, 1.1294249535886451, tensor(-36.1982, dtype=torch.float64))\n",
      "(-32.714479059465226, 1.061608112352588, tensor(-35.2116, dtype=torch.float64))\n",
      "(-32.0903280913271, 0.9427136736825342, tensor(-34.5435, dtype=torch.float64))\n",
      "(-32.76742983352393, 1.2215823442499483, tensor(-34.6283, dtype=torch.float64))\n",
      "(-32.19811968876049, 0.8910015239488859, tensor(-34.7679, dtype=torch.float64))\n",
      "(-32.757927214372906, 1.1030751149949145, tensor(-34.3611, dtype=torch.float64))\n",
      "(-32.439945156127216, 1.024493777074134, tensor(-33.8008, dtype=torch.float64))\n",
      "(-32.869269964993, 1.1344840244963814, tensor(-36.2101, dtype=torch.float64))\n",
      "(-31.325748870708047, 0.9054559223084798, tensor(-33.1620, dtype=torch.float64))\n",
      "(-31.042300503253937, 0.9515671619415195, tensor(-32.9593, dtype=torch.float64))\n",
      "(-33.52730486176908, 1.4927005294901068, tensor(-36.3470, dtype=torch.float64))\n",
      "(-32.747226645778866, 1.048141872582559, tensor(-35.2873, dtype=torch.float64))\n",
      "(-32.71462144436315, 1.1683962077498864, tensor(-34.4016, dtype=torch.float64))\n",
      "(-32.883380431700495, 1.225014539427428, tensor(-36.2482, dtype=torch.float64))\n",
      "(-31.491022801715882, 0.7887527363975423, tensor(-33.9256, dtype=torch.float64))\n",
      "(-33.04299074325711, 1.2291579733263684, tensor(-36.2763, dtype=torch.float64))\n",
      "(-3.4583896312117575, 0.08328081168837709, tensor(-3.6641, dtype=torch.float64))\n",
      "(-32.27178090129048, 1.328412593136609, tensor(-34.1923, dtype=torch.float64))\n",
      "(-32.81382851302624, 1.1803125276109294, tensor(-34.7309, dtype=torch.float64))\n",
      "(-32.953223817944526, 1.3688269820630259, tensor(-35.9688, dtype=torch.float64))\n",
      "(-33.048406586833295, 1.2367495111156317, tensor(-36.2866, dtype=torch.float64))\n",
      "(-34.56800178147852, 2.3988672307379186, tensor(-36.0268, dtype=torch.float64))\n",
      "(-32.54507752491161, 1.0890286493869297, tensor(-35.5522, dtype=torch.float64))\n",
      "(-30.988142223358153, 0.9599559867564277, tensor(-32.6967, dtype=torch.float64))\n",
      "(-32.76960006274283, 1.0226983657253472, tensor(-34.6859, dtype=torch.float64))\n",
      "(-32.544245566185566, 1.0892565430359693, tensor(-35.5522, dtype=torch.float64))\n",
      "(-33.401102327201514, 2.5547734402011266, tensor(-35.4492, dtype=torch.float64))\n",
      "(-32.809422666020694, 1.07734446807243, tensor(-35.7425, dtype=torch.float64))\n",
      "(-31.43329231288284, 0.716264083104905, tensor(-33.5211, dtype=torch.float64))\n",
      "(-31.993380014728753, 1.0106822347904394, tensor(-34.3510, dtype=torch.float64))\n",
      "(-33.36105218071491, 1.4397023512220137, tensor(-36.5527, dtype=torch.float64))\n",
      "(-32.769594625253234, 1.0947788331250095, tensor(-35.1952, dtype=torch.float64))\n",
      "(-31.779355893898757, 0.8048699881500506, tensor(-34.3383, dtype=torch.float64))\n",
      "(-32.78326095290482, 1.1625914022416575, tensor(-34.3845, dtype=torch.float64))\n",
      "(-31.3820671736449, 0.7923956802675404, tensor(-33.4018, dtype=torch.float64))\n",
      "(-32.135521990545094, 0.9810181057702678, tensor(-34.7881, dtype=torch.float64))\n",
      "(-32.71000077202916, 1.1678731096592438, tensor(-34.7238, dtype=torch.float64))\n",
      "(-32.75924653232098, 1.1346974229094042, tensor(-35.4559, dtype=torch.float64))\n",
      "(-33.32273370873183, 1.585675026753273, tensor(-36.6520, dtype=torch.float64))\n",
      "(-32.91284643067047, 1.2140637505257754, tensor(-36.2292, dtype=torch.float64))\n",
      "(-32.785032123234124, 1.0898091547482374, tensor(-34.2228, dtype=torch.float64))\n",
      "(-32.51512396818027, 1.1338002736698394, tensor(-35.6225, dtype=torch.float64))\n",
      "(-32.894813253059986, 2.0198582174813344, tensor(-34.4586, dtype=torch.float64))\n",
      "(-32.8000259745121, 1.0826495136947252, tensor(-33.3235, dtype=torch.float64))\n",
      "(-30.489456439744682, 2.0496458328797726, tensor(-32.5636, dtype=torch.float64))\n",
      "(-33.81389407623559, 1.687200290914871, tensor(-36.8294, dtype=torch.float64))\n",
      "(-32.85571674123406, 1.2131627333665658, tensor(-35.8630, dtype=torch.float64))\n",
      "(-32.138761854544285, 0.9884667252617295, tensor(-35.1199, dtype=torch.float64))\n",
      "(-33.28396577941254, 1.3304403460902512, tensor(-36.4371, dtype=torch.float64))\n",
      "(-32.75318047938868, 1.0225650852787953, tensor(-35.0927, dtype=torch.float64))\n",
      "(-32.69539270833135, 1.086557068211285, tensor(-35.1626, dtype=torch.float64))\n",
      "(-32.76586044007912, 1.1577831645702448, tensor(-35.7368, dtype=torch.float64))\n",
      "(-31.673451928496362, 0.9056837031049025, tensor(-33.7353, dtype=torch.float64))\n",
      "(-32.7681363947317, 1.044551098534676, tensor(-34.9296, dtype=torch.float64))\n",
      "(-31.13685496635735, 1.1387203757323792, tensor(-33.0153, dtype=torch.float64))\n",
      "(-31.449274747371675, 0.8498465629810202, tensor(-33.6298, dtype=torch.float64))\n",
      "(-32.75889152560383, 1.0595374522877181, tensor(-35.6113, dtype=torch.float64))\n",
      "(-33.407014975249766, 2.324370740831901, tensor(-34.9118, dtype=torch.float64))\n",
      "(-32.948269667178394, 1.2720124982368761, tensor(-36.2015, dtype=torch.float64))\n",
      "(-31.137649521827697, 0.8853460647104824, tensor(-33.1524, dtype=torch.float64))\n",
      "(-32.68578852908686, 1.1166334218924008, tensor(-34.9216, dtype=torch.float64))\n",
      "(-29.351381773333998, 3.8720112590293256, tensor(-33.8664, dtype=torch.float64))\n",
      "(-32.71476923964918, 1.0755232429177624, tensor(-34.6004, dtype=torch.float64))\n",
      "(-32.763377973325554, 1.1526651542397828, tensor(-35.4572, dtype=torch.float64))\n",
      "(-31.495587795600294, 0.7763595514253597, tensor(-33.9454, dtype=torch.float64))\n",
      "(-33.65511444801464, 1.5509176548251664, tensor(-36.6017, dtype=torch.float64))\n",
      "(-31.48390513382852, 0.7265431911788539, tensor(-33.8716, dtype=torch.float64))\n",
      "(-31.26823945114389, 0.8949688099123482, tensor(-32.8862, dtype=torch.float64))\n",
      "(-32.76348347421735, 1.1990423624346171, tensor(-34.7326, dtype=torch.float64))\n",
      "(-31.06494963169098, 0.7805732791608276, tensor(-32.8434, dtype=torch.float64))\n",
      "(-32.435162824299184, 1.1552964639528787, tensor(-33.5998, dtype=torch.float64))\n",
      "(-34.24990866649896, 1.9927267862745142, tensor(-37.0548, dtype=torch.float64))\n",
      "(-32.85480677032843, 1.2521183133438372, tensor(-36.0848, dtype=torch.float64))\n",
      "(-33.20099373634905, 1.914532918657355, tensor(-36.8786, dtype=torch.float64))\n",
      "(-32.85313570000231, 1.2396227342547865, tensor(-36.0765, dtype=torch.float64))\n",
      "(-32.490925055891275, 0.9862848405833321, tensor(-35.6639, dtype=torch.float64))\n",
      "(-32.749442368224265, 1.2320633845496582, tensor(-35.8205, dtype=torch.float64))\n",
      "(-32.90444895967841, 1.2556128247532246, tensor(-35.9969, dtype=torch.float64))\n",
      "(-29.9085416347906, 3.509630106580039, tensor(-33.3235, dtype=torch.float64))\n",
      "(-33.83459534725174, 1.6956967503021803, tensor(-36.8671, dtype=torch.float64))\n",
      "(-33.175686703845855, 1.780013050400429, tensor(-36.2090, dtype=torch.float64))\n",
      "(-31.21508090252057, 1.053109228150629, tensor(-33.0698, dtype=torch.float64))\n",
      "(-32.780974736008794, 1.0924942026005926, tensor(-34.7625, dtype=torch.float64))\n",
      "(-29.625074131935836, 3.467652085394786, tensor(-33.6308, dtype=torch.float64))\n",
      "(-33.19769626736641, 1.9399046049142639, tensor(-36.8638, dtype=torch.float64))\n",
      "(-31.838389254435896, 0.7998331369627264, tensor(-34.5592, dtype=torch.float64))\n",
      "(-32.80292840125039, 1.0961770901783179, tensor(-35.9807, dtype=torch.float64))\n",
      "(-32.727973671518264, 1.2055826595702612, tensor(-34.4656, dtype=torch.float64))\n",
      "(-32.82524653855711, 1.121394740235305, tensor(-35.8030, dtype=torch.float64))\n",
      "(-31.461242893263698, 0.8391814449274839, tensor(-33.4706, dtype=torch.float64))\n",
      "(-31.130858209133148, 0.7672260693166082, tensor(-33.0536, dtype=torch.float64))\n",
      "(-32.773013042602685, 1.0603350752876302, tensor(-34.7284, dtype=torch.float64))\n",
      "(-3.459023045003414, 0.08481597096477445, tensor(-3.6726, dtype=torch.float64))\n",
      "(-34.197876171022656, 2.178783933451966, tensor(-36.4566, dtype=torch.float64))\n",
      "(-32.740013428274544, 1.1207024430922958, tensor(-34.3869, dtype=torch.float64))\n",
      "(-32.6981700929068, 1.0691334454929091, tensor(-35.1445, dtype=torch.float64))\n",
      "(-32.777760846484455, 1.1902967782306022, tensor(-34.9418, dtype=torch.float64))\n",
      "(-32.74469405330718, 1.0609051978003186, tensor(-35.0976, dtype=torch.float64))\n",
      "(-32.69820919798687, 1.2125003393100506, tensor(-34.9702, dtype=torch.float64))\n",
      "(-31.08344845816493, 2.2384560451636566, tensor(-33.9622, dtype=torch.float64))\n",
      "(-31.34048139743507, 0.8787382693274611, tensor(-33.0691, dtype=torch.float64))\n",
      "(-32.90070756703615, 1.2085171967313255, tensor(-36.2368, dtype=torch.float64))\n",
      "(-3.4487092533707617, 0.09835552179728593, tensor(-3.6546, dtype=torch.float64))\n",
      "(-32.738947776351125, 1.1496554745326202, tensor(-35.7858, dtype=torch.float64))\n",
      "(-31.71500342719257, 0.8606625700344942, tensor(-34.0650, dtype=torch.float64))\n",
      "(-31.792330268919468, 0.8099204695922262, tensor(-34.3375, dtype=torch.float64))\n",
      "(-33.32079367587343, 1.4825554704687176, tensor(-36.5530, dtype=torch.float64))\n",
      "(-32.73984043797478, 1.149869910272545, tensor(-35.6534, dtype=torch.float64))\n",
      "(-32.82338126456365, 1.0512942584759115, tensor(-34.5039, dtype=torch.float64))\n",
      "(-30.781653143819423, 1.6569176108252206, tensor(-33.4824, dtype=torch.float64))\n",
      "(-32.53068683268502, 1.1425720884691997, tensor(-35.5560, dtype=torch.float64))\n",
      "(-32.77033821873367, 1.101447931206326, tensor(-35.7504, dtype=torch.float64))\n",
      "(-32.6773207911104, 1.1481220533678553, tensor(-35.0628, dtype=torch.float64))\n",
      "(-0.9484221694618463, 0.16316809784247965, tensor(-0.9783, dtype=torch.float64))\n",
      "(-3.434454121887684, 0.16001453857331352, tensor(-3.6705, dtype=torch.float64))\n",
      "(-32.751855996213855, 1.1101589301777814, tensor(-35.2548, dtype=torch.float64))\n",
      "(-32.692211922407154, 1.1514629593603374, tensor(-35.1378, dtype=torch.float64))\n",
      "(-31.25417168363929, 2.499080393654867, tensor(-33.6164, dtype=torch.float64))\n",
      "(-32.79874678725377, 1.0497177487798162, tensor(-34.8251, dtype=torch.float64))\n",
      "(-30.678114342689515, 1.1374553428388479, tensor(-32.4353, dtype=torch.float64))\n",
      "(-32.32557048739866, 1.1703039191768343, tensor(-35.0216, dtype=torch.float64))\n",
      "(-33.81204904288054, 1.6787939721270084, tensor(-36.8598, dtype=torch.float64))\n",
      "(-32.70886321654543, 1.1125755719004864, tensor(-35.3743, dtype=torch.float64))\n",
      "(-32.97616774493829, 1.3139889401620564, tensor(-36.0294, dtype=torch.float64))\n",
      "(-32.77904384449124, 1.1700272368040328, tensor(-34.6581, dtype=torch.float64))\n",
      "(-31.13299705028534, 0.8802180088558407, tensor(-33.1428, dtype=torch.float64))\n",
      "(-32.854118436947466, 1.2464372726915445, tensor(-36.0779, dtype=torch.float64))\n",
      "(-33.17693256134167, 1.3787394475431853, tensor(-36.3093, dtype=torch.float64))\n",
      "(-3.4442041337490084, 0.11662898227722893, tensor(-3.6443, dtype=torch.float64))\n",
      "(-32.82407407438382, 1.146866971478382, tensor(-35.8465, dtype=torch.float64))\n",
      "(-32.216046819128096, 1.4023041991480176, tensor(-34.1309, dtype=torch.float64))\n",
      "(-32.70288419015706, 1.1135857357672794, tensor(-34.6224, dtype=torch.float64))\n",
      "(-32.730778331104666, 1.0569514912478042, tensor(-34.4507, dtype=torch.float64))\n",
      "(-32.23604163303971, 1.4021747472508788, tensor(-34.1705, dtype=torch.float64))\n",
      "(-32.78648451503366, 1.119137781083616, tensor(-33.2263, dtype=torch.float64))\n",
      "(-32.86932126928121, 1.1342735220815812, tensor(-36.2160, dtype=torch.float64))\n",
      "(-32.77419796783477, 1.1067722456235123, tensor(-34.4748, dtype=torch.float64))\n",
      "(-32.7429873197712, 1.1564110239420196, tensor(-35.0361, dtype=torch.float64))\n",
      "(-32.85541779659688, 1.1645513201674798, tensor(-36.2360, dtype=torch.float64))\n",
      "(-31.266709531657398, 1.7457796846086209, tensor(-33.0353, dtype=torch.float64))\n",
      "(-32.858059587869796, 1.1301066056139188, tensor(-35.8763, dtype=torch.float64))\n",
      "(-33.5030104463175, 1.582450753216154, tensor(-36.1212, dtype=torch.float64))\n",
      "(-32.732217084039, 1.071923108809968, tensor(-35.3940, dtype=torch.float64))\n",
      "(-3.4207889162003995, 0.274876295786056, tensor(-3.6366, dtype=torch.float64))\n",
      "(-32.748050082288685, 1.0466523912085304, tensor(-35.1111, dtype=torch.float64))\n",
      "(-33.346614842358974, 1.4045504779535536, tensor(-36.6137, dtype=torch.float64))\n",
      "(-32.52487162541598, 1.678668917659182, tensor(-34.3322, dtype=torch.float64))\n",
      "(-32.17487673159689, 0.9755413459739699, tensor(-35.2144, dtype=torch.float64))\n",
      "(-32.765525653269144, 1.1121286084785578, tensor(-35.7553, dtype=torch.float64))\n",
      "(-32.70687453282997, 1.0770030661252648, tensor(-34.9669, dtype=torch.float64))\n",
      "(-32.41923043148592, 1.060720790451266, tensor(-34.4710, dtype=torch.float64))\n",
      "(-33.32001611620188, 1.5793833896672698, tensor(-36.6348, dtype=torch.float64))\n",
      "(-33.175908637549725, 1.3113703142351665, tensor(-36.0695, dtype=torch.float64))\n",
      "(-0.7835979847982526, 0.12982319175058632, tensor(-0.6651, dtype=torch.float64))\n",
      "(-32.861335913408546, 1.1572189329576061, tensor(-36.2470, dtype=torch.float64))\n",
      "(-31.47949416015297, 0.7952288044363762, tensor(-33.8757, dtype=torch.float64))\n",
      "(-31.45627669138834, 2.3491955233634325, tensor(-33.6277, dtype=torch.float64))\n",
      "(-32.70624079585075, 1.0491583151432098, tensor(-35.0136, dtype=torch.float64))\n",
      "(-31.844184968024493, 0.7979463220076314, tensor(-34.5801, dtype=torch.float64))\n",
      "(-31.820782063733787, 0.7925024751349211, tensor(-34.6212, dtype=torch.float64))\n",
      "(-31.49519510447979, 0.7775379002265516, tensor(-33.9433, dtype=torch.float64))\n",
      "(-33.72796532321721, 1.6253483907775959, tensor(-36.9240, dtype=torch.float64))\n",
      "(-32.10219204420224, 0.9621448758822486, tensor(-34.3299, dtype=torch.float64))\n",
      "(-31.313593174461275, 1.2833755306113628, tensor(-33.6201, dtype=torch.float64))\n",
      "(-32.688555596303196, 1.1787675276522063, tensor(-34.2941, dtype=torch.float64))\n",
      "(-31.74931365855038, 0.9499763095014374, tensor(-33.7025, dtype=torch.float64))\n",
      "(-0.6386962722614408, 0.4764398865685568, tensor(1.5158, dtype=torch.float64))\n",
      "(-32.17044723462313, 0.9845122320489101, tensor(-35.2182, dtype=torch.float64))\n",
      "(-32.77811516227201, 1.014532596111078, tensor(-35.5631, dtype=torch.float64))\n",
      "(-32.85445139367133, 1.209555012700066, tensor(-36.2397, dtype=torch.float64))\n",
      "(-32.77767482785508, 1.1434699327867048, tensor(-33.8938, dtype=torch.float64))\n",
      "(-32.07310409422964, 0.9303353207380515, tensor(-34.9046, dtype=torch.float64))\n",
      "(-32.68431306337938, 1.097869805984151, tensor(-34.8527, dtype=torch.float64))\n",
      "(-32.67345011495054, 1.1904991414476407, tensor(-34.4663, dtype=torch.float64))\n",
      "(-31.490825595520437, 0.7737461640786346, tensor(-33.9115, dtype=torch.float64))\n",
      "(-25.548894858360292, 3.4971821648793684, tensor(-26.7854, dtype=torch.float64))\n",
      "(-32.857531034071, 1.2481502084166325, tensor(-36.0829, dtype=torch.float64))\n",
      "(-32.756908639091996, 1.0529105637832967, tensor(-35.6078, dtype=torch.float64))\n",
      "(-32.390280740913006, 1.0045671598145887, tensor(-34.8784, dtype=torch.float64))\n",
      "(-32.783468949794766, 1.0944682999721158, tensor(-35.7774, dtype=torch.float64))\n",
      "(-34.24465369746089, 1.9385676715630433, tensor(-36.9762, dtype=torch.float64))\n",
      "(-32.87078671848401, 1.1987888234398802, tensor(-33.4158, dtype=torch.float64))\n",
      "(-32.85222644643858, 1.2064908267818755, tensor(-36.2420, dtype=torch.float64))\n",
      "(-32.78919350568205, 1.0584464600057448, tensor(-35.1682, dtype=torch.float64))\n",
      "(-32.090152804218235, 0.9310083682396894, tensor(-34.7647, dtype=torch.float64))\n",
      "(-31.246674829274415, 1.0360455439327645, tensor(-33.0868, dtype=torch.float64))\n",
      "(-33.31795943886041, 1.6460681555101353, tensor(-36.2633, dtype=torch.float64))\n",
      "(-32.74074267102405, 1.2661375692129129, tensor(-34.5870, dtype=torch.float64))\n",
      "(-32.74204241877422, 1.2239015825769455, tensor(-34.1824, dtype=torch.float64))\n",
      "(-32.71702606031671, 1.1303401992780318, tensor(-34.3035, dtype=torch.float64))\n",
      "(-31.47987252516672, 0.793540732572681, tensor(-33.8772, dtype=torch.float64))\n",
      "(-32.761873590871694, 1.1284088493619464, tensor(-34.9573, dtype=torch.float64))\n",
      "(-32.18188681686297, 0.9096028576389418, tensor(-35.2670, dtype=torch.float64))\n",
      "(-32.63818343712017, 1.244297155872591, tensor(-35.0820, dtype=torch.float64))\n",
      "(-32.68550133537501, 1.0956977361950586, tensor(-35.0405, dtype=torch.float64))\n",
      "(-32.08243849556893, 1.0290328581611725, tensor(-34.6982, dtype=torch.float64))\n",
      "(-31.480705783851445, 0.7852520190294628, tensor(-33.8695, dtype=torch.float64))\n",
      "(-33.73418349564076, 1.6141469020769148, tensor(-36.3949, dtype=torch.float64))\n",
      "(-32.781632016971706, 1.0826725857513735, tensor(-34.9283, dtype=torch.float64))\n",
      "(-32.803391909319906, 1.1204040083399691, tensor(-35.6322, dtype=torch.float64))\n",
      "(-32.79932572502643, 1.151469841530539, tensor(-34.6862, dtype=torch.float64))\n",
      "(-33.74648395134136, 1.5021499877257045, tensor(-36.8448, dtype=torch.float64))\n",
      "(-31.784189213197678, 0.7818508984036892, tensor(-34.3924, dtype=torch.float64))\n",
      "(-31.139737317562105, 0.9833004910299616, tensor(-33.1364, dtype=torch.float64))\n",
      "(-32.40398441303521, 1.0521016635435827, tensor(-35.2919, dtype=torch.float64))\n",
      "(-31.333240161798894, 2.4901618175305757, tensor(-33.9510, dtype=torch.float64))\n",
      "(-32.09560129709542, 0.9280207948445572, tensor(-34.9943, dtype=torch.float64))\n",
      "(-32.73748772772029, 1.1057845915088798, tensor(-34.2011, dtype=torch.float64))\n",
      "(-32.47190098335967, 1.0224633506085796, tensor(-35.5918, dtype=torch.float64))\n",
      "(-32.856039794050155, 1.0809206983045139, tensor(-33.3798, dtype=torch.float64))\n",
      "(-32.805648834910244, 1.1733306504953545, tensor(-35.2883, dtype=torch.float64))\n",
      "(-32.188220080137256, 0.9628028756409339, tensor(-35.1929, dtype=torch.float64))\n",
      "(-31.12496274428442, 2.0727462035985145, tensor(-33.9095, dtype=torch.float64))\n",
      "(-32.75062088130042, 1.0825430507557634, tensor(-34.3368, dtype=torch.float64))\n",
      "(-32.74052952051163, 1.095268905330827, tensor(-34.7930, dtype=torch.float64))\n",
      "(-32.9487427723594, 1.269632399786358, tensor(-36.2017, dtype=torch.float64))\n",
      "(-32.743936679139736, 1.2433625434143099, tensor(-33.4503, dtype=torch.float64))\n",
      "(-33.48081271609291, 1.8175818281165115, tensor(-36.3476, dtype=torch.float64))\n",
      "(-33.298879886437206, 1.5519157807429915, tensor(-36.6012, dtype=torch.float64))\n",
      "(-31.34031227108091, 1.4199053401779749, tensor(-33.3902, dtype=torch.float64))\n",
      "(-32.7376141471602, 0.9881475576109984, tensor(-35.3065, dtype=torch.float64))\n",
      "(-31.54993909249082, 1.4041120222580337, tensor(-34.0576, dtype=torch.float64))\n",
      "(-33.2342510086298, 1.3636433510315387, tensor(-36.3719, dtype=torch.float64))\n",
      "(-32.86978057010099, 1.1346795572021986, tensor(-36.2150, dtype=torch.float64))\n",
      "(-32.44431355221197, 1.029504268285022, tensor(-34.4004, dtype=torch.float64))\n",
      "(-32.7756201937981, 1.0531577243378671, tensor(-34.6285, dtype=torch.float64))\n",
      "(-32.764320083707574, 1.1818098019786283, tensor(-34.7744, dtype=torch.float64))\n",
      "(-31.11065896987915, 0.8288627413396891, tensor(-33.0971, dtype=torch.float64))\n",
      "(-32.74732803700492, 1.0998057702020756, tensor(-35.8580, dtype=torch.float64))\n",
      "(-32.939687150977555, 1.3128034066948626, tensor(-35.9325, dtype=torch.float64))\n",
      "(-32.0681827192381, 0.9586433890739015, tensor(-34.9124, dtype=torch.float64))\n",
      "(-31.37121402557939, 1.940449921675238, tensor(-33.5463, dtype=torch.float64))\n",
      "(-31.367438370678574, 1.3044502365942383, tensor(-33.4925, dtype=torch.float64))\n",
      "(-32.78329580679536, 1.108023879928529, tensor(-35.8443, dtype=torch.float64))\n",
      "(-33.34686999341473, 1.4043550297200746, tensor(-36.6128, dtype=torch.float64))\n",
      "(-32.83505546109751, 1.139964579261471, tensor(-34.9945, dtype=torch.float64))\n",
      "(-32.173253788165745, 0.9158484077473212, tensor(-35.1853, dtype=torch.float64))\n",
      "(-32.734041349887846, 1.112937734453445, tensor(-34.8463, dtype=torch.float64))\n",
      "(-33.33869549434632, 1.522493402087856, tensor(-36.2321, dtype=torch.float64))\n",
      "(-30.290390297640116, 2.709136334516485, tensor(-32.8791, dtype=torch.float64))\n",
      "(-32.147741823308166, 0.9084468829786105, tensor(-35.3427, dtype=torch.float64))\n",
      "(-32.845215439777824, 1.1379415629882177, tensor(-36.1368, dtype=torch.float64))\n",
      "(-32.7765229697898, 1.1009111927142687, tensor(-35.6423, dtype=torch.float64))\n",
      "(-32.87165160279721, 1.1722396101438326, tensor(-36.0030, dtype=torch.float64))\n",
      "(-32.774539831820874, 1.1145234622041893, tensor(-34.3355, dtype=torch.float64))\n",
      "(-32.72500359633938, 1.0608657287966026, tensor(-35.0291, dtype=torch.float64))\n",
      "(-33.06040853023529, 1.7364959832265892, tensor(-35.7063, dtype=torch.float64))\n",
      "(-32.72389378592372, 1.1185167807537566, tensor(-35.0008, dtype=torch.float64))\n",
      "(-32.1726715496555, 0.992457524247275, tensor(-35.2328, dtype=torch.float64))\n",
      "(-32.69588099502027, 1.1096474009782613, tensor(-34.5756, dtype=torch.float64))\n",
      "(-32.552995557636024, 1.0547362639659734, tensor(-35.5167, dtype=torch.float64))\n",
      "(-32.85825853863731, 1.2027710667762788, tensor(-36.2245, dtype=torch.float64))\n",
      "(-33.30945035196841, 1.5429015288616936, tensor(-36.6058, dtype=torch.float64))\n",
      "(-31.970042803604155, 1.0354448709602155, tensor(-34.2855, dtype=torch.float64))\n",
      "(-31.045481951236724, 0.7579150933208992, tensor(-32.7431, dtype=torch.float64))\n",
      "(-32.677033648863436, 1.257481560405592, tensor(-35.0489, dtype=torch.float64))\n",
      "(-31.457567562684417, 0.7573754367602621, tensor(-33.7278, dtype=torch.float64))\n",
      "(-32.41208578364924, 1.086325779005352, tensor(-35.3230, dtype=torch.float64))\n",
      "(-0.6768868151307106, 0.36653499741508627, tensor(-0.5833, dtype=torch.float64))\n",
      "(-31.109685833454133, 0.7429473215684831, tensor(-33.0034, dtype=torch.float64))\n",
      "(-31.08939076423645, 0.8029443079967487, tensor(-32.9869, dtype=torch.float64))\n",
      "(-33.511141511444, 1.7114803890116488, tensor(-35.8520, dtype=torch.float64))\n",
      "(-34.64585632193834, 2.326779522004009, tensor(-36.7370, dtype=torch.float64))\n",
      "(-33.271349054798485, 1.535464711164367, tensor(-36.5652, dtype=torch.float64))\n",
      "(-33.725714772958305, 1.61431180219401, tensor(-36.8742, dtype=torch.float64))\n",
      "(-32.756033965609966, 1.0885891766652203, tensor(-34.8871, dtype=torch.float64))\n",
      "(-32.711079441588375, 1.108175852057645, tensor(-34.6023, dtype=torch.float64))\n",
      "(-32.7836718233116, 1.1232182229482612, tensor(-35.2662, dtype=torch.float64))\n",
      "(-32.44541426612064, 1.0778654510768035, tensor(-35.3079, dtype=torch.float64))\n",
      "(-32.79907803434879, 1.0624895853024452, tensor(-35.1763, dtype=torch.float64))\n",
      "(-32.872284413632, 1.1439773954535613, tensor(-36.2684, dtype=torch.float64))\n",
      "(-31.14157467126846, 0.9701258686161733, tensor(-33.1745, dtype=torch.float64))\n",
      "(-31.84591517858207, 0.8234666953503802, tensor(-34.6174, dtype=torch.float64))\n",
      "(-33.27666711403057, 1.5668395892614564, tensor(-36.2741, dtype=torch.float64))\n",
      "(-32.751994152534756, 1.1060701630180487, tensor(-34.3961, dtype=torch.float64))\n",
      "(-32.7672809776105, 1.1852172118255366, tensor(-35.0036, dtype=torch.float64))\n",
      "(-32.76476022895426, 1.08840092564352, tensor(-34.7013, dtype=torch.float64))\n",
      "(-32.713434774223714, 1.2079712936772526, tensor(-35.5812, dtype=torch.float64))\n",
      "(-25.553975188732146, 3.480147869617574, tensor(-26.5423, dtype=torch.float64))\n",
      "(-32.546745440810916, 1.0213870860469239, tensor(-35.7710, dtype=torch.float64))\n",
      "(-32.54070534612983, 1.0307032139009364, tensor(-35.7703, dtype=torch.float64))\n",
      "(-31.115700221061708, 0.757095557669176, tensor(-33.0301, dtype=torch.float64))\n",
      "(-32.731655387561766, 1.1204980690987185, tensor(-35.2950, dtype=torch.float64))\n",
      "(-32.94717857660726, 1.2772664326777865, tensor(-36.1991, dtype=torch.float64))\n",
      "(-32.81623975943774, 1.0685800718073604, tensor(-34.7372, dtype=torch.float64))\n",
      "(-33.408671741355214, 1.840149286966335, tensor(-35.6470, dtype=torch.float64))\n",
      "(-32.815010915584864, 1.2018804630192732, tensor(-34.5683, dtype=torch.float64))\n",
      "(-32.68807063413784, 1.0974964707695205, tensor(-34.8968, dtype=torch.float64))\n",
      "(-32.91416973130777, 1.2225500625736194, tensor(-36.2768, dtype=torch.float64))\n",
      "(-32.726593918986616, 1.109766365806429, tensor(-34.1633, dtype=torch.float64))\n",
      "(-31.058637580871583, 0.8235611773574464, tensor(-32.8201, dtype=torch.float64))\n",
      "(-32.94386532571167, 1.2527102803073986, tensor(-36.1838, dtype=torch.float64))\n",
      "(-32.73346125755459, 1.208473617294579, tensor(-35.3940, dtype=torch.float64))\n",
      "(-32.73468861266971, 1.1216437482411952, tensor(-35.3079, dtype=torch.float64))\n",
      "(-31.813307595364748, 0.7762875923345486, tensor(-34.5134, dtype=torch.float64))\n",
      "(-31.731197105254978, 0.7847644081296242, tensor(-33.8469, dtype=torch.float64))\n",
      "(-32.64237080898136, 1.194967804015172, tensor(-34.3081, dtype=torch.float64))\n",
      "(-32.81980462709442, 1.1505579150260077, tensor(-34.7025, dtype=torch.float64))\n",
      "(-32.4120041038841, 1.1424582548098452, tensor(-34.0112, dtype=torch.float64))\n",
      "(-32.842166571132836, 1.130789743615405, tensor(-36.1412, dtype=torch.float64))\n",
      "(-32.40072743970901, 1.1447927243201397, tensor(-34.9842, dtype=torch.float64))\n",
      "(-32.74975200239569, 1.0522272581395913, tensor(-35.4019, dtype=torch.float64))\n",
      "(-32.546811561100185, 1.0597762716919636, tensor(-35.7543, dtype=torch.float64))\n",
      "(-32.717528261318805, 1.1388121818844745, tensor(-34.3399, dtype=torch.float64))\n",
      "(-31.730631292797625, 0.9525161826842012, tensor(-33.7459, dtype=torch.float64))\n",
      "(-33.495662965308874, 1.882430579095009, tensor(-35.7905, dtype=torch.float64))\n",
      "(-33.68743735721335, 1.6401026827940435, tensor(-36.1450, dtype=torch.float64))\n",
      "(-32.51570227686316, 1.6431151886752662, tensor(-34.3112, dtype=torch.float64))\n",
      "(-31.46809239458293, 0.8075523534942973, tensor(-33.8229, dtype=torch.float64))\n",
      "(-32.858268174100665, 1.15367601016794, tensor(-35.8974, dtype=torch.float64))\n",
      "(-27.828483873270454, 4.409389234525643, tensor(-31.7634, dtype=torch.float64))\n",
      "(-32.32826901700348, 1.1766980082532454, tensor(-34.2359, dtype=torch.float64))\n",
      "(-32.790724462848154, 1.084556868304957, tensor(-34.5892, dtype=torch.float64))\n",
      "(-32.78209546605125, 1.1696994525405502, tensor(-34.2153, dtype=torch.float64))\n",
      "(-32.73179358405992, 1.1547436294805697, tensor(-34.6978, dtype=torch.float64))\n",
      "(-33.12990866817534, 1.6866604795396023, tensor(-35.5473, dtype=torch.float64))\n",
      "(-32.87508577922359, 1.1436172685596455, tensor(-36.2674, dtype=torch.float64))\n",
      "(-32.772946331258865, 1.0637043210344057, tensor(-34.7330, dtype=torch.float64))\n",
      "(-32.40632868763059, 1.1016322434346986, tensor(-34.2383, dtype=torch.float64))\n",
      "(-31.496089728958903, 0.7772298805175467, tensor(-33.9451, dtype=torch.float64))\n",
      "(-32.50713520864025, 1.0734677732859506, tensor(-34.6276, dtype=torch.float64))\n",
      "(-30.948950911574066, 1.3512507468110757, tensor(-32.6963, dtype=torch.float64))\n",
      "(-32.74215400684625, 1.2382283642243461, tensor(-33.6968, dtype=torch.float64))\n",
      "(-31.12036657333374, 0.7449024139924658, tensor(-33.0201, dtype=torch.float64))\n",
      "(-31.088327372074126, 0.754562552859458, tensor(-32.9183, dtype=torch.float64))\n",
      "(-32.87186292028055, 1.1426508383948903, tensor(-36.1765, dtype=torch.float64))\n",
      "(-32.18690512191504, 0.969365781919436, tensor(-35.1893, dtype=torch.float64))\n",
      "(-32.69533689117059, 1.0824690881686105, tensor(-35.1991, dtype=torch.float64))\n",
      "(-33.810198549367485, 1.6874947081287968, tensor(-36.8783, dtype=torch.float64))\n",
      "(-32.44065916184336, 1.0711791014607812, tensor(-35.2055, dtype=torch.float64))\n",
      "(-32.73048931352794, 1.098698238834723, tensor(-34.6607, dtype=torch.float64))\n",
      "(-32.81312028402463, 1.1103697460271078, tensor(-35.9232, dtype=torch.float64))\n",
      "(-32.68666096676141, 1.1360176588145396, tensor(-34.7929, dtype=torch.float64))\n",
      "(-31.586229054089635, 3.0088444228901596, tensor(-33.6184, dtype=torch.float64))\n",
      "(-31.75621428117156, 0.8306352513958368, tensor(-34.3572, dtype=torch.float64))\n",
      "(-31.09027808189392, 0.7853390882545799, tensor(-32.9827, dtype=torch.float64))\n",
      "(-32.55362825110555, 1.0649064680525573, tensor(-35.3619, dtype=torch.float64))\n",
      "(-32.418569601569324, 0.9696501919066612, tensor(-35.1230, dtype=torch.float64))\n",
      "(-33.398218597248196, 1.5111650934642433, tensor(-36.5661, dtype=torch.float64))\n",
      "(-32.174843556899575, 0.8988633307068555, tensor(-35.2592, dtype=torch.float64))\n",
      "(-32.704499721489846, 1.1009429736753058, tensor(-34.9104, dtype=torch.float64))\n",
      "(-32.38890369132161, 1.1449722399240154, tensor(-33.1402, dtype=torch.float64))\n",
      "(-32.84999222397804, 1.205015000680361, tensor(-36.2365, dtype=torch.float64))\n",
      "(-33.476080469172445, 1.7915196994593843, tensor(-36.3078, dtype=torch.float64))\n",
      "(-32.75785834681243, 1.064558227814345, tensor(-33.9706, dtype=torch.float64))\n",
      "(-32.73395322499797, 1.123068223238649, tensor(-34.2801, dtype=torch.float64))\n",
      "(-32.73659131884575, 1.1124276851984185, tensor(-34.7499, dtype=torch.float64))\n",
      "(-33.262974674776196, 2.31361590886761, tensor(-35.5349, dtype=torch.float64))\n",
      "(-32.731301539670675, 1.1184070496963223, tensor(-34.7011, dtype=torch.float64))\n",
      "(-29.29573428859934, 3.7908868822615993, tensor(-33.3181, dtype=torch.float64))\n",
      "(-32.78703026356175, 1.1418025643370777, tensor(-35.4730, dtype=torch.float64))\n",
      "(-31.136462140083314, 0.8968054993493053, tensor(-33.1515, dtype=torch.float64))\n",
      "(-32.689647594355044, 1.121959057505502, tensor(-34.5180, dtype=torch.float64))\n",
      "(-31.304988981094212, 2.0455512463693317, tensor(-34.0677, dtype=torch.float64))\n",
      "(-32.75246205745265, 1.1703407341771455, tensor(-34.4907, dtype=torch.float64))\n",
      "(-31.80084833070636, 0.8738109556094181, tensor(-34.4959, dtype=torch.float64))\n",
      "(-32.82945155441761, 1.0342912701032978, tensor(-34.9050, dtype=torch.float64))\n",
      "(-32.8021015938744, 1.0961710893554175, tensor(-35.9811, dtype=torch.float64))\n",
      "(-31.45920992422849, 0.7902556526945126, tensor(-33.8314, dtype=torch.float64))\n",
      "(-31.83737252727151, 0.8319506012246489, tensor(-34.5376, dtype=torch.float64))\n",
      "(-33.296139793023464, 1.5460943962104772, tensor(-36.6096, dtype=torch.float64))\n",
      "(-32.85324870388955, 1.2058756077845658, tensor(-36.2423, dtype=torch.float64))\n",
      "(-32.54195354709402, 1.0306012312757107, tensor(-35.8034, dtype=torch.float64))\n",
      "(-32.84078997500241, 1.183926144244951, tensor(-36.1915, dtype=torch.float64))\n",
      "(-32.85265592623502, 1.1074968943072039, tensor(-36.0339, dtype=torch.float64))\n",
      "(-33.528352855984124, 1.5796600268612395, tensor(-36.2539, dtype=torch.float64))\n",
      "(-32.527796021346006, 1.0570250888862367, tensor(-35.7579, dtype=torch.float64))\n",
      "(-32.786484524849804, 1.1191377166262946, tensor(-33.2263, dtype=torch.float64))\n",
      "(-32.73289199350402, 1.0687699169915406, tensor(-35.3181, dtype=torch.float64))\n",
      "(-32.159064716100694, 0.9768694475975306, tensor(-34.9246, dtype=torch.float64))\n",
      "(-32.37840251205489, 1.076416645920426, tensor(-33.8504, dtype=torch.float64))\n",
      "(-32.72470526231453, 1.0636174702496035, tensor(-34.8981, dtype=torch.float64))\n",
      "(-31.99009764716029, 1.0887942029699929, tensor(-34.1921, dtype=torch.float64))\n",
      "(-31.469763719048352, 0.8075103983103848, tensor(-33.8574, dtype=torch.float64))\n",
      "(-30.548930422794072, 1.6715407567668488, tensor(-32.7198, dtype=torch.float64))\n",
      "(-32.41442029695958, 1.0841768468616566, tensor(-35.1693, dtype=torch.float64))\n",
      "(-32.707410675138235, 1.0737076934091216, tensor(-35.3021, dtype=torch.float64))\n",
      "(-30.99482382297516, 0.8921625289984895, tensor(-32.5876, dtype=torch.float64))\n",
      "(-31.984547569304706, 1.2348072226360558, tensor(-34.0005, dtype=torch.float64))\n",
      "(-32.83913593903184, 1.085767444120337, tensor(-35.6662, dtype=torch.float64))\n",
      "(-33.31368496328592, 1.613520147072463, tensor(-36.2672, dtype=torch.float64))\n",
      "(-32.86837446724996, 1.1540025313714009, tensor(-36.2568, dtype=torch.float64))\n",
      "(-28.71739192990586, 4.277813739082568, tensor(-33.4646, dtype=torch.float64))\n",
      "(-34.26043716687709, 1.9916304136665448, tensor(-37.0272, dtype=torch.float64))\n",
      "(-32.554420010484755, 1.108795891209754, tensor(-35.5300, dtype=torch.float64))\n",
      "(-32.80287111230194, 1.1128780877090296, tensor(-35.9086, dtype=torch.float64))\n",
      "(-32.07271041769534, 0.9431454258270557, tensor(-34.8924, dtype=torch.float64))\n",
      "(-32.795229057110845, 1.092588465052025, tensor(-35.8739, dtype=torch.float64))\n",
      "(-0.633244600072503, 0.4805676116916932, tensor(0.4005, dtype=torch.float64))\n",
      "(-31.781372108496726, 0.7688406712152461, tensor(-34.2586, dtype=torch.float64))\n",
      "(-32.183199835754934, 0.9496264294980455, tensor(-35.1620, dtype=torch.float64))\n",
      "(-32.69689149865881, 1.188124574837339, tensor(-33.8574, dtype=torch.float64))\n",
      "(-31.462574778422713, 0.8148800895065423, tensor(-33.8225, dtype=torch.float64))\n",
      "(-32.42007852209732, 0.9693811386294138, tensor(-35.0278, dtype=torch.float64))\n",
      "(-32.69844240795821, 1.0944512436566685, tensor(-35.3460, dtype=torch.float64))\n",
      "(-31.456044569537042, 0.87469464090021, tensor(-33.5037, dtype=torch.float64))\n",
      "(-33.72816168885678, 1.5074470893130387, tensor(-36.7816, dtype=torch.float64))\n",
      "(-32.81458217073232, 1.1383908309608064, tensor(-35.8375, dtype=torch.float64))\n",
      "(-32.790380421727896, 1.027701452934806, tensor(-35.5256, dtype=torch.float64))\n",
      "(-30.580596108380703, 1.5624192496214366, tensor(-32.9757, dtype=torch.float64))\n",
      "(-34.63617179047316, 2.6952036077675747, tensor(-36.5204, dtype=torch.float64))\n",
      "(-31.837934724614023, 0.8014596122513967, tensor(-34.6704, dtype=torch.float64))\n",
      "(-33.3243430695869, 1.548336379350584, tensor(-36.2511, dtype=torch.float64))\n",
      "(-31.834793045036495, 0.8386043135870846, tensor(-34.4728, dtype=torch.float64))\n",
      "(-0.6323497261479497, 0.48699334220479845, tensor(0.8377, dtype=torch.float64))\n",
      "(-31.379795955102892, 0.8089033479892094, tensor(-33.2605, dtype=torch.float64))\n",
      "(-32.179776173457505, 0.9132291868671621, tensor(-35.2668, dtype=torch.float64))\n",
      "(-31.097771611213684, 0.8185685614471641, tensor(-33.0866, dtype=torch.float64))\n",
      "(-32.74660531865433, 1.0581699508201377, tensor(-35.1783, dtype=torch.float64))\n",
      "(-31.468174278009684, 0.7666688963209882, tensor(-33.8519, dtype=torch.float64))\n",
      "(-32.75742852943018, 1.099627538121836, tensor(-34.5478, dtype=torch.float64))\n",
      "(-34.546825095787646, 2.42290466488605, tensor(-36.2182, dtype=torch.float64))\n",
      "(-32.53955685991794, 1.1238964561548805, tensor(-35.8082, dtype=torch.float64))\n",
      "(-30.52098219126463, 2.954433436072018, tensor(-34.1353, dtype=torch.float64))\n",
      "(-31.449492825083436, 0.7862301751273173, tensor(-33.0598, dtype=torch.float64))\n",
      "(-31.46131702074781, 0.8009782680984522, tensor(-33.7243, dtype=torch.float64))\n",
      "(-33.7883926101774, 1.8236605343429895, tensor(-36.4022, dtype=torch.float64))\n",
      "(-3.092556355521083, 1.1541434587668207, tensor(-3.6010, dtype=torch.float64))\n",
      "(-32.71122869392857, 1.0668530088059094, tensor(-35.0841, dtype=torch.float64))\n",
      "(-32.959523857031016, 1.2776777867194882, tensor(-36.1987, dtype=torch.float64))\n",
      "(-32.742256947606805, 1.1049600891634233, tensor(-34.7742, dtype=torch.float64))\n",
      "(-32.74821845544502, 1.1584608453003855, tensor(-34.4588, dtype=torch.float64))\n",
      "(-32.74705774234608, 1.048599223907482, tensor(-34.6690, dtype=torch.float64))\n",
      "(-31.459979062229394, 0.8344050817664775, tensor(-33.6655, dtype=torch.float64))\n",
      "(-32.391099043060095, 1.0766820172626494, tensor(-34.1665, dtype=torch.float64))\n",
      "(-32.75286129783839, 1.1126314926705476, tensor(-34.1685, dtype=torch.float64))\n",
      "(-33.7735691235587, 1.6290142633970413, tensor(-36.7255, dtype=torch.float64))\n",
      "(-32.86899322379381, 1.132884725671913, tensor(-36.1936, dtype=torch.float64))\n",
      "(-32.772840934563426, 1.1693059476160894, tensor(-35.8970, dtype=torch.float64))\n",
      "(-32.689936744440345, 1.1151139098203942, tensor(-35.0947, dtype=torch.float64))\n",
      "(-32.81051613138989, 1.0655457668107584, tensor(-35.9422, dtype=torch.float64))\n",
      "(-31.469502054508776, 0.7552556617950296, tensor(-33.8535, dtype=torch.float64))\n",
      "(-32.747770543266085, 1.0379893049487925, tensor(-35.2637, dtype=torch.float64))\n",
      "(-32.41467511156574, 1.0650043713903028, tensor(-34.5336, dtype=torch.float64))\n",
      "(-31.81220372816548, 0.8008832727336513, tensor(-34.5864, dtype=torch.float64))\n",
      "(-32.70959156490862, 1.1743144289047438, tensor(-35.2041, dtype=torch.float64))\n",
      "(-32.946310262568296, 1.2544642765418146, tensor(-36.2060, dtype=torch.float64))\n",
      "(-32.89515299167484, 1.8255701480008713, tensor(-34.4564, dtype=torch.float64))\n",
      "(-32.780752970464526, 1.0494466878392494, tensor(-34.6657, dtype=torch.float64))\n",
      "(-32.79442245887592, 1.1032589962359256, tensor(-34.3354, dtype=torch.float64))\n",
      "(-32.09113122979179, 0.9532309816477361, tensor(-34.4578, dtype=torch.float64))\n",
      "(-32.8182599036023, 1.181837726433334, tensor(-34.7311, dtype=torch.float64))\n",
      "(-31.142230455875396, 0.9695828365510885, tensor(-33.1781, dtype=torch.float64))\n",
      "(-32.51928396785632, 1.004260264695672, tensor(-35.7488, dtype=torch.float64))\n",
      "(-32.74143563874066, 1.121748790798164, tensor(-35.0386, dtype=torch.float64))\n",
      "(-32.75159677281976, 1.0926503096266953, tensor(-34.3598, dtype=torch.float64))\n",
      "(-34.63336208641529, 2.6868166843129053, tensor(-36.5223, dtype=torch.float64))\n",
      "(-32.556446779277174, 1.0570182550491423, tensor(-35.7394, dtype=torch.float64))\n",
      "(-32.83702490473166, 1.1248603924195137, tensor(-33.6346, dtype=torch.float64))\n",
      "(-31.47947273362428, 0.784724915330679, tensor(-33.8798, dtype=torch.float64))\n",
      "(-32.4217591310665, 1.0376365909091356, tensor(-34.1154, dtype=torch.float64))\n",
      "(-32.691624010652305, 1.1190454566804917, tensor(-34.4463, dtype=torch.float64))\n",
      "(-31.47473500924185, 0.7848406360011612, tensor(-33.8525, dtype=torch.float64))\n",
      "(-32.543539750669154, 1.014437423362633, tensor(-35.7566, dtype=torch.float64))\n",
      "(-32.74060580128804, 1.20967642457498, tensor(-34.1077, dtype=torch.float64))\n",
      "(-32.465378535054626, 1.5796240631782954, tensor(-34.3263, dtype=torch.float64))\n",
      "(-31.836453540325167, 0.7919771078698299, tensor(-34.5174, dtype=torch.float64))\n",
      "(-32.742158389166, 1.2245199525225905, tensor(-34.5989, dtype=torch.float64))\n",
      "(-32.810393767040225, 1.1095217447473247, tensor(-35.5534, dtype=torch.float64))\n",
      "(-33.700513546951115, 1.535490085888684, tensor(-36.7222, dtype=torch.float64))\n",
      "(-32.555425084605815, 0.9969451754087173, tensor(-35.8090, dtype=torch.float64))\n",
      "(-32.800518790706995, 1.1112300855826833, tensor(-35.8926, dtype=torch.float64))\n",
      "(-32.8124495697394, 1.085768990706794, tensor(-35.9273, dtype=torch.float64))\n",
      "(-32.828294307813046, 1.1275647459724207, tensor(-35.9534, dtype=torch.float64))\n",
      "(-32.761165717430416, 1.34430622862076, tensor(-35.3508, dtype=torch.float64))\n",
      "(-33.08690923174843, 1.272120065054587, tensor(-33.3326, dtype=torch.float64))\n",
      "(-32.83316942825913, 1.169920503706381, tensor(-35.3591, dtype=torch.float64))\n",
      "(-32.78288728354499, 1.1085489810294524, tensor(-35.7913, dtype=torch.float64))\n",
      "(-32.70072748832405, 1.012584772363744, tensor(-35.4432, dtype=torch.float64))\n",
      "(-31.768452237118037, 0.8541002173515125, tensor(-34.2876, dtype=torch.float64))\n",
      "(-31.46152850748971, 0.8171320988111307, tensor(-33.8010, dtype=torch.float64))\n",
      "(-32.77865273665637, 1.1202138233144177, tensor(-33.9836, dtype=torch.float64))\n",
      "(-32.76775150842965, 1.0371471528442768, tensor(-35.4878, dtype=torch.float64))\n",
      "(-0.9460368572920561, 0.1330300664885457, tensor(-0.9996, dtype=torch.float64))\n",
      "(-32.712115643285216, 1.2067087328580326, tensor(-35.5817, dtype=torch.float64))\n",
      "(-32.61296697052196, 1.579616828721718, tensor(-34.2593, dtype=torch.float64))\n",
      "(-32.76951718373224, 1.041825761107266, tensor(-35.5646, dtype=torch.float64))\n",
      "(-31.478761022370307, 0.7974852088982902, tensor(-33.8768, dtype=torch.float64))\n",
      "(-31.80507000040263, 0.7782851102369596, tensor(-34.5361, dtype=torch.float64))\n",
      "(-31.79533511782065, 0.7850975882160486, tensor(-34.4965, dtype=torch.float64))\n",
      "(-32.53958267616108, 1.0185260660138176, tensor(-35.8046, dtype=torch.float64))\n",
      "(-32.697980855684726, 1.1254067056142343, tensor(-34.8465, dtype=torch.float64))\n",
      "(-31.492397133186458, 1.45454673613686, tensor(-34.2922, dtype=torch.float64))\n",
      "(-32.832793542556466, 1.2078054165582381, tensor(-36.0322, dtype=torch.float64))\n",
      "(-32.8647039815411, 1.148457486953711, tensor(-36.1370, dtype=torch.float64))\n",
      "(-30.19933752298355, 1.5894671726548464, tensor(-31.7587, dtype=torch.float64))\n",
      "(-32.708526012077925, 1.1003520425368034, tensor(-34.5408, dtype=torch.float64))\n",
      "(-32.709983724988994, 1.0074821172667536, tensor(-35.4971, dtype=torch.float64))\n",
      "(-31.27643702682108, 2.5759453262844367, tensor(-33.1542, dtype=torch.float64))\n",
      "(-32.74981037985533, 1.085886135542308, tensor(-34.3515, dtype=torch.float64))\n",
      "(-32.82558227483183, 1.1528180035571898, tensor(-35.9019, dtype=torch.float64))\n",
      "(-33.34321008620784, 1.4000883966823925, tensor(-36.5968, dtype=torch.float64))\n",
      "(-32.747020783443006, 1.1211156332508074, tensor(-35.0332, dtype=torch.float64))\n",
      "(-32.803190603144465, 1.0496585514310823, tensor(-34.8000, dtype=torch.float64))\n",
      "(-32.838870047479865, 1.1659046936803117, tensor(-36.1999, dtype=torch.float64))\n",
      "(-33.54797167280689, 1.9923353961747017, tensor(-34.8791, dtype=torch.float64))\n",
      "(-32.738704250659794, 1.2320541208938807, tensor(-34.5976, dtype=torch.float64))\n",
      "(-32.81013333391398, 1.1254905669542385, tensor(-35.9250, dtype=torch.float64))\n",
      "(-31.001081206798553, 0.8729561984598526, tensor(-32.7142, dtype=torch.float64))\n",
      "(-32.11812689607963, 0.8965640522934425, tensor(-34.9209, dtype=torch.float64))\n",
      "(-32.64156679069623, 1.197212096678956, tensor(-34.7040, dtype=torch.float64))\n",
      "(-32.806172258518636, 1.093171019074123, tensor(-35.7823, dtype=torch.float64))\n",
      "(-32.068765300549565, 1.0137729876875239, tensor(-34.6446, dtype=torch.float64))\n",
      "(-32.7519515712373, 1.2178839846933531, tensor(-33.7119, dtype=torch.float64))\n",
      "(-32.75352545326576, 1.1279574806364818, tensor(-33.8847, dtype=torch.float64))\n",
      "(-32.7630535746552, 1.1088767295420576, tensor(-35.9506, dtype=torch.float64))\n",
      "(-31.454743983391673, 0.8503504844592367, tensor(-33.5633, dtype=torch.float64))\n",
      "(-32.36103049952537, 1.2469896438679982, tensor(-34.3587, dtype=torch.float64))\n",
      "(-32.82282590221614, 1.140886051701654, tensor(-34.3512, dtype=torch.float64))\n",
      "(-32.916939736735074, 1.2802203150801732, tensor(-35.9923, dtype=torch.float64))\n",
      "(-32.363585861176254, 1.0339495249728314, tensor(-34.6552, dtype=torch.float64))\n",
      "(-32.66848391698673, 1.1365373418651545, tensor(-33.9615, dtype=torch.float64))\n",
      "(-31.482501348797232, 0.7837928426655677, tensor(-33.8712, dtype=torch.float64))\n",
      "(-32.87444228045642, 1.1897148819665075, tensor(-36.0138, dtype=torch.float64))\n",
      "(-31.09558963537216, 0.7566244596110676, tensor(-32.9805, dtype=torch.float64))\n",
      "(-32.793923416249456, 1.08774104200088, tensor(-34.5985, dtype=torch.float64))\n",
      "(-32.9772790990211, 1.6851717335025393, tensor(-35.1985, dtype=torch.float64))\n",
      "(-32.77667487639934, 1.1598476746465978, tensor(-35.1341, dtype=torch.float64))\n",
      "(-34.6862142021209, 2.3694863685581526, tensor(-37.0708, dtype=torch.float64))\n",
      "(-32.776957270558924, 1.070903123158997, tensor(-34.7204, dtype=torch.float64))\n",
      "(-32.71431784974411, 1.0704472211204847, tensor(-34.6563, dtype=torch.float64))\n",
      "(-31.434650542587043, 0.7578896048941007, tensor(-33.7722, dtype=torch.float64))\n",
      "(-32.77514555746689, 1.0596828867128552, tensor(-35.3816, dtype=torch.float64))\n",
      "(-32.77910234512761, 1.1274316686798689, tensor(-35.8366, dtype=torch.float64))\n",
      "(-32.83472778566182, 1.1688129717888105, tensor(-35.1057, dtype=torch.float64))\n",
      "(-32.128255157191305, 0.8651242152462351, tensor(-35.0596, dtype=torch.float64))\n",
      "(-32.78709191665053, 1.1204453887037513, tensor(-33.7770, dtype=torch.float64))\n",
      "(-25.55129682660103, 3.4795262735769343, tensor(-26.6327, dtype=torch.float64))\n",
      "(-32.772053296100346, 1.0805309421983054, tensor(-34.3507, dtype=torch.float64))\n",
      "(-32.54395776864141, 1.0242608581890147, tensor(-35.7711, dtype=torch.float64))\n",
      "(-32.81906095165759, 1.1912068399203504, tensor(-35.6846, dtype=torch.float64))\n",
      "(-32.507622521072626, 1.0652373603383882, tensor(-35.7514, dtype=torch.float64))\n",
      "(-32.19200900416821, 0.9486335669044703, tensor(-34.9173, dtype=torch.float64))\n",
      "(-31.452320999186487, 0.8532831787921914, tensor(-33.4748, dtype=torch.float64))\n",
      "(-32.71122791765258, 1.1740462163022218, tensor(-35.8407, dtype=torch.float64))\n",
      "(-32.18929003339261, 0.9089288250081495, tensor(-35.1061, dtype=torch.float64))\n",
      "(-32.70747901776806, 1.2028781538262556, tensor(-34.9181, dtype=torch.float64))\n",
      "(-32.74371112331748, 1.146891874048058, tensor(-34.3438, dtype=torch.float64))\n",
      "(-31.60160773076117, 1.5843921374701144, tensor(-33.9756, dtype=torch.float64))\n",
      "(-32.76328306753189, 1.1267820167063565, tensor(-34.2862, dtype=torch.float64))\n",
      "(-32.74625040270388, 1.1340438710128233, tensor(-35.7483, dtype=torch.float64))\n",
      "(-29.3479709244892, 3.7254109700121094, tensor(-33.2575, dtype=torch.float64))\n",
      "(-31.394876379668712, 0.8113648125819608, tensor(-33.4465, dtype=torch.float64))\n",
      "(-32.79223272051662, 1.2962816192865827, tensor(-34.3600, dtype=torch.float64))\n",
      "(-32.72072871500626, 1.203744585030382, tensor(-34.8733, dtype=torch.float64))\n",
      "(-30.92489475093782, 1.502858483688623, tensor(-32.7774, dtype=torch.float64))\n",
      "(-32.79179698916152, 1.04702970254532, tensor(-34.5194, dtype=torch.float64))\n",
      "(-32.78466560389847, 1.0786188502757492, tensor(-34.8326, dtype=torch.float64))\n",
      "(-32.8529443067126, 1.0358955839424275, tensor(-35.1264, dtype=torch.float64))\n",
      "(-32.73883510094136, 1.0445101645983121, tensor(-35.3489, dtype=torch.float64))\n",
      "(-33.343326677102596, 1.3877251253334837, tensor(-36.4296, dtype=torch.float64))\n",
      "(-31.095648028850555, 0.7705265443040531, tensor(-32.9692, dtype=torch.float64))\n",
      "(-32.75003768475726, 1.1160902845837732, tensor(-35.0927, dtype=torch.float64))\n",
      "(-32.48066955147311, 0.9769817597200516, tensor(-34.6107, dtype=torch.float64))\n",
      "(-31.34947929777205, 1.2555877282310606, tensor(-33.5946, dtype=torch.float64))\n",
      "(-32.66305307203904, 1.1156727407662728, tensor(-34.9249, dtype=torch.float64))\n",
      "(-32.81100990697742, 1.0945454891022641, tensor(-35.8851, dtype=torch.float64))\n",
      "(-32.814544389806684, 1.0560173751588753, tensor(-35.6408, dtype=torch.float64))\n",
      "(-32.76010177880526, 1.113936391687346, tensor(-34.4042, dtype=torch.float64))\n",
      "(-32.74215043047443, 1.11358975462269, tensor(-35.0365, dtype=torch.float64))\n",
      "(-29.571465657614173, 3.5164157591524035, tensor(-33.5282, dtype=torch.float64))\n",
      "(-32.69213494511321, 1.0759119110522257, tensor(-35.0351, dtype=torch.float64))\n",
      "(-31.436766359098257, 0.7465307651296255, tensor(-33.7866, dtype=torch.float64))\n",
      "(-32.71592461464927, 1.1021345769524407, tensor(-34.7855, dtype=torch.float64))\n",
      "(-32.71008902665228, 1.121453541300983, tensor(-34.9870, dtype=torch.float64))\n",
      "(-33.22360045474023, 2.207827496919496, tensor(-34.5388, dtype=torch.float64))\n",
      "(-32.18650780111551, 0.9627092191366861, tensor(-35.1829, dtype=torch.float64))\n",
      "(-32.72676423840225, 1.0455092267194912, tensor(-35.1982, dtype=torch.float64))\n",
      "(-32.7571276653558, 1.1011600506619403, tensor(-34.5006, dtype=torch.float64))\n",
      "(-32.77078928697854, 1.241901377403005, tensor(-34.2373, dtype=torch.float64))\n",
      "(-32.77469724955037, 1.127122633073416, tensor(-34.4147, dtype=torch.float64))\n",
      "(-31.475786295663564, 0.836256066664811, tensor(-33.7383, dtype=torch.float64))\n",
      "(-33.04432793486863, 1.2328350393540164, tensor(-36.2851, dtype=torch.float64))\n",
      "(-32.71578859936446, 1.2083925455337476, tensor(-35.5805, dtype=torch.float64))\n",
      "(-31.23228817978874, 0.9721048753102243, tensor(-33.0735, dtype=torch.float64))\n",
      "(-31.44360962027684, 0.7716282134065245, tensor(-33.7430, dtype=torch.float64))\n",
      "(-34.20240186080336, 2.2380202085052736, tensor(-36.5725, dtype=torch.float64))\n",
      "(-32.39200131895021, 0.9942988492762724, tensor(-34.9240, dtype=torch.float64))\n",
      "(-32.702371478229765, 1.0444294099081486, tensor(-34.9120, dtype=torch.float64))\n",
      "(-33.619323129989205, 1.6816108782927393, tensor(-35.8214, dtype=torch.float64))\n",
      "(-32.407072439622134, 1.1989790439771406, tensor(-34.0016, dtype=torch.float64))\n",
      "(-28.87044098466635, 3.4603685266063673, tensor(-32.3706, dtype=torch.float64))\n",
      "(-33.40862346291542, 1.520339760157508, tensor(-36.5613, dtype=torch.float64))\n",
      "(-33.75278382927179, 1.9142706486748977, tensor(-36.4673, dtype=torch.float64))\n",
      "(-32.699029749091714, 1.2401966589164697, tensor(-34.4329, dtype=torch.float64))\n",
      "(-31.05651222705841, 0.9217023115567731, tensor(-33.0107, dtype=torch.float64))\n",
      "(-32.68984787059948, 1.1418438428227158, tensor(-34.6864, dtype=torch.float64))\n",
      "(-33.18913948433474, 2.010258588259591, tensor(-36.8432, dtype=torch.float64))\n",
      "(-32.79137768741697, 1.1550563071452273, tensor(-34.0320, dtype=torch.float64))\n",
      "(-33.396873481199144, 1.61395584430835, tensor(-36.2186, dtype=torch.float64))\n",
      "(-32.137253021970395, 0.9986088311665596, tensor(-35.1177, dtype=torch.float64))\n",
      "(-32.767267984543, 1.1333327490812084, tensor(-34.9852, dtype=torch.float64))\n",
      "(-32.51855251099914, 1.0034153343916692, tensor(-35.7492, dtype=torch.float64))\n",
      "(-31.74484091322869, 1.592761376372264, tensor(-34.1629, dtype=torch.float64))\n",
      "(-32.68362943245098, 1.125437396325034, tensor(-34.8640, dtype=torch.float64))\n",
      "(-33.11435208370909, 1.416577732537226, tensor(-35.7712, dtype=torch.float64))\n",
      "(-32.52563364231959, 1.1076111921588705, tensor(-35.7991, dtype=torch.float64))\n",
      "(-32.366881484128534, 0.9822538889010312, tensor(-34.8392, dtype=torch.float64))\n",
      "(-32.67967225177213, 1.1758570394751695, tensor(-34.3063, dtype=torch.float64))\n",
      "(-31.099528625011445, 0.7520144564834852, tensor(-32.9686, dtype=torch.float64))\n",
      "(-31.811257058531044, 0.8723806424160269, tensor(-34.5301, dtype=torch.float64))\n",
      "(-31.128634641170503, 0.7709155355830193, tensor(-33.0598, dtype=torch.float64))\n",
      "(-29.870825566072018, 3.012078710353334, tensor(-33.5168, dtype=torch.float64))\n",
      "(-32.7823378976062, 1.0684415844887913, tensor(-34.9508, dtype=torch.float64))\n",
      "(-32.88936951445416, 1.223964470514364, tensor(-36.2639, dtype=torch.float64))\n",
      "(-32.72510228486732, 1.096072185545339, tensor(-34.9146, dtype=torch.float64))\n",
      "(-32.515167999006806, 1.1103355966537458, tensor(-34.1081, dtype=torch.float64))\n",
      "(-30.995136840343477, 0.8592650014190375, tensor(-32.6099, dtype=torch.float64))\n",
      "(-31.127020993232726, 0.7134757009082159, tensor(-32.9912, dtype=torch.float64))\n",
      "(-31.565257003344595, 1.3618302156228186, tensor(-33.2324, dtype=torch.float64))\n",
      "(-32.665393316559495, 1.2409523750395766, tensor(-35.0175, dtype=torch.float64))\n",
      "(-3.4450286239385606, 0.1273726416539785, tensor(-3.6400, dtype=torch.float64))\n",
      "(-32.73824396500364, 1.088973626814727, tensor(-34.4939, dtype=torch.float64))\n",
      "(-31.13034967277199, 1.2466274316616157, tensor(-32.8830, dtype=torch.float64))\n",
      "(-31.221685613188892, 1.0599988310241248, tensor(-33.0402, dtype=torch.float64))\n",
      "(-32.98379433205351, 1.264059639087862, tensor(-36.1229, dtype=torch.float64))\n",
      "(-32.465693790763616, 0.9930877565606737, tensor(-35.3380, dtype=torch.float64))\n",
      "(-32.72347950823605, 1.082593963337097, tensor(-34.9814, dtype=torch.float64))\n",
      "(-32.83747387755662, 1.17731911402014, tensor(-36.1985, dtype=torch.float64))\n",
      "(-32.778570921029896, 1.1075904533273706, tensor(-35.8588, dtype=torch.float64))\n",
      "(-32.74543802488595, 1.1218488268978353, tensor(-34.1583, dtype=torch.float64))\n",
      "(-32.83514180922881, 1.1885803970845652, tensor(-33.2605, dtype=torch.float64))\n",
      "(-32.751984027549625, 1.0996986905062702, tensor(-35.7377, dtype=torch.float64))\n",
      "(-33.04070462789387, 1.2307335158771255, tensor(-36.2766, dtype=torch.float64))\n",
      "(-31.099360196702182, 1.2246732740983224, tensor(-32.8916, dtype=torch.float64))\n",
      "(-32.712837250493465, 1.1208373629919648, tensor(-34.9368, dtype=torch.float64))\n",
      "(-32.732555199079215, 1.0896764603297215, tensor(-34.1661, dtype=torch.float64))\n",
      "(-32.673594420924786, 1.1746075104214941, tensor(-34.6753, dtype=torch.float64))\n",
      "(-31.456928574908524, 0.7278405159582592, tensor(-33.6956, dtype=torch.float64))\n",
      "(-31.4587187432684, 0.8536905576329433, tensor(-33.6359, dtype=torch.float64))\n",
      "(-32.76638138568029, 1.0490111801207143, tensor(-35.5711, dtype=torch.float64))\n",
      "(-33.96000007722527, 1.8283981034772596, tensor(-35.9993, dtype=torch.float64))\n",
      "(-33.32023205988109, 1.5871273238942767, tensor(-36.6518, dtype=torch.float64))\n",
      "(-30.765737653095275, 2.130422444117972, tensor(-33.6537, dtype=torch.float64))\n",
      "(-32.14643446724862, 0.9059706729373537, tensor(-35.3415, dtype=torch.float64))\n",
      "(-32.854345168676225, 1.2446114276223257, tensor(-36.0773, dtype=torch.float64))\n",
      "(-33.276103304252025, 1.5577673424239857, tensor(-36.6087, dtype=torch.float64))\n",
      "(-32.766976991761474, 1.1404499033528928, tensor(-35.7782, dtype=torch.float64))\n",
      "(-32.476039889063685, 1.0345931364766265, tensor(-35.6609, dtype=torch.float64))\n",
      "(-32.84844778686762, 1.170280084139638, tensor(-34.4111, dtype=torch.float64))\n",
      "(-31.434651795271783, 0.7476956847603268, tensor(-33.7856, dtype=torch.float64))\n",
      "(-29.186209763251245, 3.6260472280593143, tensor(-33.2627, dtype=torch.float64))\n",
      "(-32.409750224743036, 1.1974604378254283, tensor(-34.0827, dtype=torch.float64))\n",
      "(-0.9235999689996243, 0.2917557774544524, tensor(-0.9194, dtype=torch.float64))\n",
      "(-32.75235873773694, 1.1314383471640497, tensor(-34.5714, dtype=torch.float64))\n",
      "(-32.40813552364707, 1.1000419581812269, tensor(-34.7420, dtype=torch.float64))\n",
      "(-32.674573375936596, 1.0842532950109256, tensor(-34.5180, dtype=torch.float64))\n",
      "(-0.5637624595686793, 0.6485100397796009, tensor(-0.8830, dtype=torch.float64))\n",
      "(-32.81356756925583, 1.0808328600373596, tensor(-35.9742, dtype=torch.float64))\n",
      "(-32.750283750388775, 1.044165986186549, tensor(-35.1341, dtype=torch.float64))\n",
      "(-32.75356833549216, 1.0765322271348148, tensor(-35.7378, dtype=torch.float64))\n",
      "(-33.00689182959497, 1.9265109156848832, tensor(-35.5255, dtype=torch.float64))\n",
      "(-32.779682047516104, 1.161806815975583, tensor(-34.3790, dtype=torch.float64))\n",
      "(-31.44997336745262, 0.8370190831237669, tensor(-33.4812, dtype=torch.float64))\n",
      "(-32.181484730802474, 0.9149256378103457, tensor(-35.2673, dtype=torch.float64))\n",
      "(-32.79792083773762, 1.1092224033930556, tensor(-35.9433, dtype=torch.float64))\n",
      "(-32.71844005806371, 1.155526275118745, tensor(-34.9333, dtype=torch.float64))\n",
      "(-31.443823849391194, 0.8307681545639617, tensor(-33.7189, dtype=torch.float64))\n",
      "(-32.2039737554267, 0.9828733626220839, tensor(-35.0235, dtype=torch.float64))\n",
      "(-33.2520013473928, 1.581303605729048, tensor(-36.5708, dtype=torch.float64))\n",
      "(-31.08630051612854, 0.7878268197764584, tensor(-32.9966, dtype=torch.float64))\n",
      "(-32.32480988195166, 1.5803641291523278, tensor(-34.0976, dtype=torch.float64))\n",
      "(-31.475150545984505, 0.8008118333389167, tensor(-33.8293, dtype=torch.float64))\n",
      "(-32.86759897163138, 1.185904455149753, tensor(-36.0152, dtype=torch.float64))\n",
      "(-32.646910161338745, 1.1384779388431119, tensor(-34.6622, dtype=torch.float64))\n",
      "(-32.95617162404582, 1.3580677243217973, tensor(-35.9905, dtype=torch.float64))\n",
      "(-33.72915838409215, 1.6292889536041548, tensor(-36.9278, dtype=torch.float64))\n",
      "(-31.411485745664685, 0.8174168234469991, tensor(-33.5136, dtype=torch.float64))\n",
      "(-31.666904241535814, 1.0284932653224967, tensor(-33.0488, dtype=torch.float64))\n",
      "(-32.18883977904916, 0.9762331420262016, tensor(-35.1957, dtype=torch.float64))\n",
      "(-30.29275107430294, 2.1682618948716703, tensor(-32.7274, dtype=torch.float64))\n",
      "(-32.47291844468564, 1.0164078805204706, tensor(-35.6036, dtype=torch.float64))\n",
      "(-30.70864942315966, 1.4890080442028284, tensor(-32.7985, dtype=torch.float64))\n",
      "(-32.66671127818525, 1.2208800095892764, tensor(-34.9662, dtype=torch.float64))\n",
      "(-34.60040268596262, 2.3434296393407004, tensor(-36.4872, dtype=torch.float64))\n",
      "(-31.437514074780047, 2.319743261738677, tensor(-33.6949, dtype=torch.float64))\n",
      "(-32.72777191795409, 1.0700718684226094, tensor(-34.4502, dtype=torch.float64))\n",
      "(-32.77577528266236, 1.0315222120402257, tensor(-35.4015, dtype=torch.float64))\n",
      "(-32.670341446883974, 1.1398194790427616, tensor(-35.0232, dtype=torch.float64))\n",
      "(-32.715704074688254, 1.1427464686461508, tensor(-34.4467, dtype=torch.float64))\n",
      "(-32.849649597164245, 1.189668406159273, tensor(-34.5655, dtype=torch.float64))\n",
      "(-32.52423586735502, 1.0840811151264798, tensor(-35.8272, dtype=torch.float64))\n",
      "(-33.754383315891026, 1.8290526477974398, tensor(-36.4764, dtype=torch.float64))\n",
      "(-33.060671196430924, 1.214868569472916, tensor(-36.2520, dtype=torch.float64))\n",
      "(-32.886552051808685, 1.2094396212380616, tensor(-36.0125, dtype=torch.float64))\n",
      "(-32.70998694146052, 1.0074834944411248, tensor(-35.4971, dtype=torch.float64))\n",
      "(-33.316259330883625, 1.5482480159642387, tensor(-36.6070, dtype=torch.float64))\n",
      "(-31.465207537189126, 0.8023479589596137, tensor(-33.7847, dtype=torch.float64))\n",
      "(-32.1308068934083, 0.8774978516355163, tensor(-35.0751, dtype=torch.float64))\n",
      "(-30.964564159326255, 2.0036234102615884, tensor(-33.1644, dtype=torch.float64))\n",
      "(-31.114373869895935, 0.775267986797169, tensor(-33.0329, dtype=torch.float64))\n",
      "(-32.702587995491925, 1.0791688432699134, tensor(-34.5905, dtype=torch.float64))\n",
      "(-33.73461158594117, 1.4612309701482142, tensor(-36.9604, dtype=torch.float64))\n",
      "(-32.74667024549097, 1.2161979815231305, tensor(-33.7616, dtype=torch.float64))\n",
      "(-32.700121943037956, 1.093461821777587, tensor(-34.9428, dtype=torch.float64))\n",
      "(-31.611205472536383, 1.8382527214968456, tensor(-33.9106, dtype=torch.float64))\n",
      "(-32.75663040101528, 1.1198714912028145, tensor(-35.8783, dtype=torch.float64))\n",
      "(-32.54618996258825, 1.0971395302314932, tensor(-35.5289, dtype=torch.float64))\n",
      "(-28.479284652434288, 3.6592069624636756, tensor(-31.3693, dtype=torch.float64))\n",
      "(-32.43867087708786, 1.1332786156398287, tensor(-33.5619, dtype=torch.float64))\n",
      "(-32.49436604103074, 1.677685391432155, tensor(-34.5209, dtype=torch.float64))\n",
      "(-32.82783313676715, 1.1598611800984107, tensor(-35.9551, dtype=torch.float64))\n",
      "(-31.134892370700836, 0.9166197764963033, tensor(-33.1372, dtype=torch.float64))\n",
      "(-32.7612156829983, 1.0205129781929325, tensor(-34.9761, dtype=torch.float64))\n",
      "(-31.808724038898944, 0.7927935448236838, tensor(-34.5330, dtype=torch.float64))\n",
      "(-32.5377797082439, 1.0379146214545496, tensor(-35.8015, dtype=torch.float64))\n",
      "(-32.82779806012288, 1.0476467270547636, tensor(-34.8269, dtype=torch.float64))\n",
      "(-32.6769244085066, 1.144751496763897, tensor(-35.0653, dtype=torch.float64))\n",
      "(-32.74442757256329, 1.0888218588545269, tensor(-34.7554, dtype=torch.float64))\n",
      "(-31.46667362075299, 0.8300925725799962, tensor(-33.7605, dtype=torch.float64))\n",
      "(-32.16765715911984, 1.015705899909138, tensor(-35.2786, dtype=torch.float64))\n",
      "(-32.75355400383472, 1.1051357653119778, tensor(-35.5570, dtype=torch.float64))\n",
      "(-31.089460105895995, 0.8029007174688362, tensor(-32.9727, dtype=torch.float64))\n",
      "(-33.318316122852266, 1.58339855532628, tensor(-36.6391, dtype=torch.float64))\n",
      "(-32.73120039731264, 1.1692730386824282, tensor(-35.6405, dtype=torch.float64))\n",
      "(-33.582897050157186, 2.640258491325605, tensor(-34.6638, dtype=torch.float64))\n",
      "(-32.74909115316346, 1.0832171180442738, tensor(-34.9946, dtype=torch.float64))\n",
      "(-30.18724331455305, 2.535243547453804, tensor(-33.6159, dtype=torch.float64))\n",
      "(-31.134112989902498, 0.9733051637634759, tensor(-33.1583, dtype=torch.float64))\n",
      "(-32.94168423648924, 1.324590356610405, tensor(-35.9003, dtype=torch.float64))\n",
      "(-32.734837593492124, 1.099505264977166, tensor(-34.6053, dtype=torch.float64))\n",
      "(-32.727425930947064, 1.0697971186619755, tensor(-34.6529, dtype=torch.float64))\n",
      "(-31.79284069277346, 0.7819891779859037, tensor(-34.4269, dtype=torch.float64))\n",
      "(-0.6302145048230886, 0.4782391160934364, tensor(1.9512, dtype=torch.float64))\n",
      "(-34.256126761548224, 1.9874854440130723, tensor(-37.0312, dtype=torch.float64))\n",
      "(-32.775168679244814, 1.1028765080238578, tensor(-34.0134, dtype=torch.float64))\n",
      "(-33.127291520498694, 1.6084701226683462, tensor(-35.5321, dtype=torch.float64))\n",
      "(-32.39690142048523, 1.0737858379764993, tensor(-35.1243, dtype=torch.float64))\n",
      "(-30.682570480816068, 1.877865366321986, tensor(-32.8587, dtype=torch.float64))\n",
      "(-32.70132079139352, 1.2127852259731202, tensor(-34.1455, dtype=torch.float64))\n",
      "(-30.611259496174753, 1.9838160391309354, tensor(-32.8424, dtype=torch.float64))\n",
      "(-30.21144505023956, 1.630684994758453, tensor(-32.0624, dtype=torch.float64))\n",
      "(-32.80765879049897, 1.1060083636677949, tensor(-35.4753, dtype=torch.float64))\n",
      "(-33.74895534142852, 1.4831134204536638, tensor(-36.9357, dtype=torch.float64))\n",
      "(-33.72736274413764, 1.6287768363981086, tensor(-36.9295, dtype=torch.float64))\n",
      "(-32.78602589372545, 1.1531814888808143, tensor(-34.0185, dtype=torch.float64))\n",
      "(-30.670173314809798, 2.4210129246197774, tensor(-32.8402, dtype=torch.float64))\n",
      "(-32.764150528330354, 1.1016462055826317, tensor(-35.9912, dtype=torch.float64))\n",
      "(-32.41961846400052, 1.5848795735333272, tensor(-34.4650, dtype=torch.float64))\n",
      "(-33.27913889613003, 1.5560113808015357, tensor(-36.5955, dtype=torch.float64))\n",
      "(-32.76653750332073, 1.1817841781978735, tensor(-34.8193, dtype=torch.float64))\n",
      "(-32.060746675375846, 1.088496611893366, tensor(-34.6149, dtype=torch.float64))\n",
      "(-32.93071716845036, 1.3054653665520877, tensor(-35.9368, dtype=torch.float64))\n",
      "(-32.74811986187473, 1.1543833073262237, tensor(-35.6720, dtype=torch.float64))\n",
      "(-32.14125085595995, 0.9872943959128945, tensor(-34.9990, dtype=torch.float64))\n",
      "(-32.8712034201622, 1.1942403386351006, tensor(-36.0147, dtype=torch.float64))\n",
      "(-32.51789618244395, 1.003195911906302, tensor(-35.7494, dtype=torch.float64))\n",
      "(-32.419083698019385, 0.9945837615822668, tensor(-34.5015, dtype=torch.float64))\n",
      "(-33.815719186365605, 1.7008458658299124, tensor(-36.8936, dtype=torch.float64))\n",
      "(-32.81548672571778, 1.0618543880905091, tensor(-35.9461, dtype=torch.float64))\n",
      "(-32.85288014331832, 1.1520634532190923, tensor(-34.9419, dtype=torch.float64))\n",
      "(-33.802650817092506, 1.675619251933582, tensor(-36.7974, dtype=torch.float64))\n",
      "(-32.735021202675995, 1.0609839462482722, tensor(-35.0714, dtype=torch.float64))\n",
      "(-32.689639938194304, 1.2381412115484933, tensor(-35.7139, dtype=torch.float64))\n",
      "(-32.77365023497492, 1.1468883675786303, tensor(-34.8325, dtype=torch.float64))\n",
      "(-31.098639483451844, 0.7574581135734325, tensor(-32.9550, dtype=torch.float64))\n",
      "(-32.38418964836747, 1.0390335084706341, tensor(-34.6083, dtype=torch.float64))\n",
      "(-32.531168580967936, 1.0434585162229728, tensor(-35.7796, dtype=torch.float64))\n",
      "(-32.94177940174937, 1.2497529730390622, tensor(-36.2138, dtype=torch.float64))\n",
      "(-31.07687665462494, 0.7392460950291678, tensor(-32.7123, dtype=torch.float64))\n",
      "(-33.74423220327124, 1.515992764658924, tensor(-36.8022, dtype=torch.float64))\n",
      "(-32.92407018119469, 1.2973039616244448, tensor(-35.9495, dtype=torch.float64))\n",
      "(-32.761697336304934, 1.0904930227772371, tensor(-34.3668, dtype=torch.float64))\n",
      "(-33.19009755000472, 1.2715278454476182, tensor(-36.3216, dtype=torch.float64))\n",
      "(-32.55486339753494, 1.0566351599097978, tensor(-35.7511, dtype=torch.float64))\n",
      "(-33.73434575965628, 1.46216233288906, tensor(-36.9603, dtype=torch.float64))\n",
      "(-32.93519650682807, 1.3109932949033265, tensor(-35.9261, dtype=torch.float64))\n",
      "(-31.057167801856995, 0.7871259598417666, tensor(-32.8314, dtype=torch.float64))\n",
      "(-32.755380177441985, 1.1196827346058627, tensor(-34.9423, dtype=torch.float64))\n",
      "(-32.802883709166196, 1.0878213415441031, tensor(-35.1248, dtype=torch.float64))\n",
      "(-30.936425483953208, 1.695307368396184, tensor(-33.4782, dtype=torch.float64))\n",
      "(-33.10355257958174, 1.6922465139157967, tensor(-35.5777, dtype=torch.float64))\n",
      "(-32.768637715596704, 1.1504240147286695, tensor(-35.7695, dtype=torch.float64))\n",
      "(-32.70073307648301, 1.1732142797073557, tensor(-35.1482, dtype=torch.float64))\n",
      "(-32.39861274752766, 1.0569529876874495, tensor(-34.3312, dtype=torch.float64))\n",
      "(-32.76572896020487, 1.0972914493813397, tensor(-35.9883, dtype=torch.float64))\n",
      "(-32.76732016844675, 1.0581733669158353, tensor(-34.4263, dtype=torch.float64))\n",
      "(-33.038493667244914, 1.7012200034040124, tensor(-35.8505, dtype=torch.float64))\n",
      "(-32.73611895315349, 1.0912119536826685, tensor(-34.7862, dtype=torch.float64))\n",
      "(-32.7186104063876, 1.0563781826894258, tensor(-34.5518, dtype=torch.float64))\n",
      "(-32.75049640672282, 1.020439618861455, tensor(-35.4693, dtype=torch.float64))\n",
      "(-32.7423675644584, 1.125556685823272, tensor(-35.0179, dtype=torch.float64))\n",
      "(-32.71184066971764, 1.0693364018697222, tensor(-34.6824, dtype=torch.float64))\n",
      "(-32.75778609570116, 1.0878178379165568, tensor(-35.8808, dtype=torch.float64))\n",
      "(-32.065579609200356, 0.9442624196719651, tensor(-34.9421, dtype=torch.float64))\n",
      "(-33.31660874076188, 1.5872133830002644, tensor(-36.6475, dtype=torch.float64))\n",
      "(-32.18827908724546, 0.991006440032989, tensor(-35.1579, dtype=torch.float64))\n",
      "(-32.77457886679098, 1.1570824984021566, tensor(-35.4662, dtype=torch.float64))\n",
      "(-31.058286239970474, 1.1269291370910948, tensor(-33.0269, dtype=torch.float64))\n",
      "(-32.854159703738986, 1.2497040104649801, tensor(-36.0858, dtype=torch.float64))\n",
      "(-31.45766261793673, 0.8549639038016675, tensor(-33.4697, dtype=torch.float64))\n",
      "(-32.55483111478388, 1.1078269675945933, tensor(-35.4764, dtype=torch.float64))\n",
      "(-30.962379336357117, 0.9086270110294801, tensor(-32.5636, dtype=torch.float64))\n",
      "(-32.78055633770302, 1.235189876142939, tensor(-35.9916, dtype=torch.float64))\n",
      "(-32.77629515204578, 1.0591938887693622, tensor(-34.7208, dtype=torch.float64))\n",
      "(-31.47844851549715, 1.1016210720667738, tensor(-33.8785, dtype=torch.float64))\n",
      "(-32.721418087091294, 1.1047694912462163, tensor(-35.1460, dtype=torch.float64))\n",
      "(-32.823383490778504, 1.0512933269981293, tensor(-34.5039, dtype=torch.float64))\n",
      "(-31.445692357514055, 0.8385186537327516, tensor(-32.7497, dtype=torch.float64))\n",
      "(-31.003968789577485, 0.8710551836585642, tensor(-32.6556, dtype=torch.float64))\n",
      "(-30.95133833169937, 0.9431451260317314, tensor(-32.4297, dtype=torch.float64))\n",
      "(-32.783875286486, 1.0386919732159865, tensor(-34.4311, dtype=torch.float64))\n",
      "(-31.460473236273973, 1.9468381453188761, tensor(-33.4944, dtype=torch.float64))\n",
      "(-32.865520147737115, 1.2349289056168982, tensor(-36.1149, dtype=torch.float64))\n",
      "(-31.76922347635031, 0.8805738184087537, tensor(-34.1855, dtype=torch.float64))\n",
      "(-32.746029882468285, 1.1113733737408669, tensor(-34.3940, dtype=torch.float64))\n",
      "(-32.77283482315019, 1.1209865392330447, tensor(-34.3240, dtype=torch.float64))\n",
      "(-31.135717079639434, 0.8527860627841395, tensor(-33.1109, dtype=torch.float64))\n",
      "(-32.742647825088355, 1.1686098960621862, tensor(-35.7804, dtype=torch.float64))\n",
      "(-33.273991683386264, 1.4354524842888485, tensor(-36.2895, dtype=torch.float64))\n",
      "(-3.4343311089277266, 0.15964750415630408, tensor(-3.6678, dtype=torch.float64))\n",
      "(-32.845075789354745, 1.078045962314729, tensor(-35.3371, dtype=torch.float64))\n",
      "(-32.695919470954685, 1.1747260145798666, tensor(-34.4631, dtype=torch.float64))\n",
      "(-32.750058247707784, 1.0587995983641678, tensor(-35.2830, dtype=torch.float64))\n",
      "(-32.82685603477061, 1.1835201573404812, tensor(-33.6832, dtype=torch.float64))\n",
      "(-34.685982841961085, 2.369759087561841, tensor(-37.0761, dtype=torch.float64))\n",
      "(-32.65250807706266, 1.1821153811405871, tensor(-34.3649, dtype=torch.float64))\n",
      "(-32.71056364115328, 1.2650963059449323, tensor(-34.7380, dtype=torch.float64))\n",
      "(-32.77503148922697, 1.1051750464310024, tensor(-35.4757, dtype=torch.float64))\n",
      "(-32.77877489877865, 1.0980012810760695, tensor(-35.3397, dtype=torch.float64))\n",
      "(-32.80330233823508, 1.0928668221111197, tensor(-35.7241, dtype=torch.float64))\n",
      "(-34.62969902325422, 2.676295920031052, tensor(-36.5230, dtype=torch.float64))\n",
      "(-32.83768103633076, 1.1339954471700064, tensor(-35.8578, dtype=torch.float64))\n",
      "(-31.006953494548796, 0.8023110786491465, tensor(-32.6767, dtype=torch.float64))\n",
      "(-0.9493403708189726, 0.1373541253123929, tensor(-0.9897, dtype=torch.float64))\n",
      "(-33.35158610286191, 1.5072173703660743, tensor(-36.5776, dtype=torch.float64))\n",
      "(-33.081500114165244, 1.7047531374764542, tensor(-35.6886, dtype=torch.float64))\n",
      "(-31.60743358105421, 1.0434100623550508, tensor(-32.9625, dtype=torch.float64))\n",
      "(-32.447772695422174, 0.9973141885727719, tensor(-35.5236, dtype=torch.float64))\n",
      "(-33.17965222310275, 1.538186894135103, tensor(-36.5954, dtype=torch.float64))\n",
      "(-32.85259037066251, 1.1797483121166468, tensor(-35.6811, dtype=torch.float64))\n",
      "(-32.5416195454821, 1.0317157293322456, tensor(-35.5902, dtype=torch.float64))\n",
      "(-32.87203165477142, 1.1934850199309395, tensor(-36.0146, dtype=torch.float64))\n",
      "(-33.04547738688066, 1.3380345009681052, tensor(-34.2946, dtype=torch.float64))\n",
      "(-31.811238160803914, 0.8501293985961041, tensor(-33.1808, dtype=torch.float64))\n",
      "(-32.81015840429813, 1.0830115479678644, tensor(-35.2018, dtype=torch.float64))\n",
      "(-32.52257252974436, 1.6900560999568903, tensor(-34.3288, dtype=torch.float64))\n",
      "(-33.126207826212045, 1.5047325647875616, tensor(-35.5956, dtype=torch.float64))\n",
      "(-32.75816387837753, 1.1571610777855836, tensor(-34.3002, dtype=torch.float64))\n",
      "(-32.73349542779848, 1.1039248361557894, tensor(-34.8528, dtype=torch.float64))\n",
      "(-32.78448261084035, 1.0744431687852147, tensor(-35.7208, dtype=torch.float64))\n",
      "(-31.48643435364589, 0.7976074034222342, tensor(-33.8933, dtype=torch.float64))\n",
      "(-31.823662049546837, 0.8222430099163065, tensor(-34.6615, dtype=torch.float64))\n",
      "(-31.4759509938024, 0.7871355736986994, tensor(-33.8670, dtype=torch.float64))\n",
      "(-32.77116095768288, 1.175388736321953, tensor(-34.7596, dtype=torch.float64))\n",
      "(-32.23328535141423, 1.2573684926566655, tensor(-34.7844, dtype=torch.float64))\n",
      "(-31.296179937850685, 0.9306426231479702, tensor(-33.0144, dtype=torch.float64))\n",
      "(-31.71055428078398, 0.8274936427188113, tensor(-33.7706, dtype=torch.float64))\n",
      "(-32.7476087124832, 1.0473615539067098, tensor(-34.7496, dtype=torch.float64))\n",
      "(-33.72333325235173, 1.507810094999897, tensor(-36.7684, dtype=torch.float64))\n",
      "(-32.81802140638232, 1.0698228759786779, tensor(-34.7132, dtype=torch.float64))\n",
      "(-32.7661370123364, 1.1152967597179493, tensor(-35.5620, dtype=torch.float64))\n",
      "(-31.448353793881832, 0.8561309815796566, tensor(-33.6270, dtype=torch.float64))\n",
      "(-32.790605758223684, 1.0964490572352172, tensor(-35.8451, dtype=torch.float64))\n",
      "(-32.542974838651716, 1.6165385050253933, tensor(-34.3502, dtype=torch.float64))\n",
      "(-32.74289311394095, 1.033965377142643, tensor(-35.1700, dtype=torch.float64))\n",
      "(-33.251187871731815, 2.1744530375214315, tensor(-34.5480, dtype=torch.float64))\n",
      "(-32.185956555455924, 0.9355493205587107, tensor(-35.0651, dtype=torch.float64))\n",
      "(-31.751505904868246, 1.5446976216411317, tensor(-33.6838, dtype=torch.float64))\n",
      "(-33.345180217064915, 1.4048105990690667, tensor(-36.6109, dtype=torch.float64))\n",
      "(-31.32585109356791, 1.0074753636812939, tensor(-32.9959, dtype=torch.float64))\n",
      "(-32.24943614747375, 1.3611072969707343, tensor(-34.1839, dtype=torch.float64))\n",
      "(-30.70856338739395, 1.1932660510794368, tensor(-32.3214, dtype=torch.float64))\n",
      "(-32.65289321513846, 1.1245376663198556, tensor(-34.7569, dtype=torch.float64))\n",
      "(-32.740424603987485, 1.1107726363544692, tensor(-34.5574, dtype=torch.float64))\n",
      "(-30.96373983422294, 1.4747256635716814, tensor(-32.9322, dtype=torch.float64))\n",
      "(-31.112250089645386, 0.8631086990355316, tensor(-33.0974, dtype=torch.float64))\n",
      "(-32.81551112087443, 1.1599339379586173, tensor(-35.9842, dtype=torch.float64))\n",
      "(-31.08505845308304, 0.910090555613513, tensor(-33.0752, dtype=torch.float64))\n",
      "(-32.76440824141726, 1.1234607858293637, tensor(-34.1291, dtype=torch.float64))\n",
      "(-31.83727487254888, 0.8309506269275532, tensor(-34.6022, dtype=torch.float64))\n",
      "(-32.182923079505564, 0.9001369314574474, tensor(-35.2260, dtype=torch.float64))\n",
      "(-0.9410280572250486, 0.3238673226660683, tensor(-0.9450, dtype=torch.float64))\n",
      "(-32.09310685185716, 0.9173240240487185, tensor(-34.7988, dtype=torch.float64))\n",
      "(-32.49658561194315, 1.524496200025576, tensor(-34.3306, dtype=torch.float64))\n",
      "(-31.449842081274838, 0.8688997740692389, tensor(-33.5157, dtype=torch.float64))\n",
      "(-32.80428672606126, 1.0901488504930248, tensor(-35.7805, dtype=torch.float64))\n",
      "(-31.09604551076889, 0.773660747055707, tensor(-32.9153, dtype=torch.float64))\n",
      "(-33.33256122015417, 1.4218167499936523, tensor(-36.4736, dtype=torch.float64))\n",
      "(-32.7724764575623, 1.1206521355795958, tensor(-34.2195, dtype=torch.float64))\n",
      "(-32.77426709018648, 1.1109180880482028, tensor(-35.1856, dtype=torch.float64))\n",
      "(-32.12241589244455, 0.940329254788659, tensor(-35.0247, dtype=torch.float64))\n",
      "(-31.3236446528323, 0.9417200171437846, tensor(-33.0172, dtype=torch.float64))\n",
      "(-32.74489845529199, 1.0688617376793261, tensor(-34.6330, dtype=torch.float64))\n",
      "(-30.47835353391245, 2.98088961597863, tensor(-33.5305, dtype=torch.float64))\n",
      "(-30.420262476820497, 2.628146805058488, tensor(-33.6262, dtype=torch.float64))\n",
      "(-32.76310712259263, 1.0791694378032428, tensor(-35.3804, dtype=torch.float64))\n",
      "(-32.89762896025553, 1.2882979673358428, tensor(-35.9571, dtype=torch.float64))\n",
      "(-32.84168612897396, 1.1002117638904427, tensor(-34.8257, dtype=torch.float64))\n",
      "(-32.79925120759756, 1.0765642442611558, tensor(-35.9274, dtype=torch.float64))\n",
      "(-0.9525363958626986, 0.15202759738112168, tensor(-0.9891, dtype=torch.float64))\n",
      "(-32.804863359648735, 1.1533963668082963, tensor(-35.9179, dtype=torch.float64))\n",
      "(-32.69746182449162, 1.1334393058829484, tensor(-34.9066, dtype=torch.float64))\n",
      "(-29.60058293133974, 3.5435398968640186, tensor(-33.2025, dtype=torch.float64))\n",
      "(-32.75249008405954, 1.1878557699038501, tensor(-34.0193, dtype=torch.float64))\n",
      "(-33.389021949227896, 1.6234168123447272, tensor(-36.2108, dtype=torch.float64))\n",
      "(-32.80035941146314, 1.096345224036941, tensor(-35.9816, dtype=torch.float64))\n",
      "(-33.193352822680026, 1.7826051451308254, tensor(-36.1913, dtype=torch.float64))\n",
      "(-31.448130947258324, 0.8513953705306175, tensor(-33.4809, dtype=torch.float64))\n",
      "(-32.53072584161535, 1.2931291873940165, tensor(-33.9793, dtype=torch.float64))\n",
      "(-32.7212448573485, 1.0187622379649688, tensor(-35.3383, dtype=torch.float64))\n"
     ]
    }
   ],
   "source": [
    "for i in zip(mu['_RETURN']['mean'], mu['_RETURN']['std'], grp_energy):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[39m=\u001b[39m BayesianNetAtoms(net\u001b[39m.\u001b[39mfunctions, net\u001b[39m.\u001b[39mspecies, net\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m      3\u001b[0m pyro\u001b[39m.\u001b[39mrender_model(model, model_args\u001b[39m=\u001b[39m([torch\u001b[39m.\u001b[39mones(\u001b[39m108\u001b[39m, \u001b[39m52\u001b[39m),torch\u001b[39m.\u001b[39mones(\u001b[39m108\u001b[39m, \u001b[39m52\u001b[39m)], [torch\u001b[39m.\u001b[39mones([\u001b[39m4\u001b[39m, \u001b[39m108\u001b[39m]),torch\u001b[39m.\u001b[39mones([\u001b[39m4\u001b[39m, \u001b[39m108\u001b[39m])], torch\u001b[39m.\u001b[39mones(\u001b[39m4\u001b[39m,)))\u001b[39m#,grp_energy))\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "model = BayesianNetAtoms(net.functions, net.species, net.device)\n",
    "\n",
    "pyro.render_model(model, model_args=([torch.ones(108, 52),torch.ones(108, 52)], [torch.ones([4, 108]),torch.ones([4, 108])], torch.ones(4,)))#,grp_energy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Initialize dataloader\n",
    "grouped_train_loader = DataLoader(grouped_train_data, batch_size=1, shuffle=False,\n",
    "                                  collate_fn=custom_collate, num_workers=0)\n",
    "grouped_valid_loader = DataLoader(grouped_valid_data, batch_size=1, shuffle=False,\n",
    "                                  collate_fn=custom_collate, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_batch in grouped_train_loader:\n",
    "    grp_descrp, grp_energy, logic_reduce = data_batch[0][10], data_batch[0][11], data_batch[0][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-27.0000, -17.8317,   2.4570,   3.1589], dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 108])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logic_reduce[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_descrp[0] = grp_descrp[0].float()\n",
    "logic_reduce[0] =logic_reduce[0].float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 302.2620, -196.0373,  209.5111,  309.6779], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(grp_descrp, logic_reduce, grp_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "\nTrace Shapes:\n Param Sites:\nSample Sites:",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py:174\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/nn/module.py:449\u001b[0m, in \u001b[0;36mPyroModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context:\n\u001b[0;32m--> 449\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    450\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    451\u001b[0m     pyro\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalidate_poutine\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context\u001b[39m.\u001b[39mactive\n\u001b[1;32m    453\u001b[0m     \u001b[39mand\u001b[39;00m _is_module_local_param_enabled()\n\u001b[1;32m    454\u001b[0m ):\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/module.py:201\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Defines the computation performed at every call.\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \n\u001b[1;32m    193\u001b[0m \u001b[39mShould be overridden by all subclasses.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m    registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49msvi\u001b[39m.\u001b[39;49mstep(grp_descrp, logic_reduce,grp_energy)\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/infer/svi.py:145\u001b[0m, in \u001b[0;36mSVI.step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39m# get loss and compute gradients\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39mwith\u001b[39;00m poutine\u001b[39m.\u001b[39mtrace(param_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m param_capture:\n\u001b[0;32m--> 145\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_and_grads(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mguide, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    147\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\n\u001b[1;32m    148\u001b[0m     site[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39munconstrained() \u001b[39mfor\u001b[39;00m site \u001b[39min\u001b[39;00m param_capture\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39mnodes\u001b[39m.\u001b[39mvalues()\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[39m# actually perform gradient steps\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001b[39;00m\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/infer/tracegraph_elbo.py:353\u001b[0m, in \u001b[0;36mTraceGraph_ELBO.loss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mloss_and_grads\u001b[39m(\u001b[39mself\u001b[39m, model, guide, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    345\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[39m    :returns: returns an estimate of the ELBO\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[39m    :rtype: float\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39m    If baselines are present, a baseline loss is also constructed and differentiated.\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 353\u001b[0m     elbo, surrogate_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_loss_and_surrogate_loss(model, guide, args, kwargs)\n\u001b[1;32m    355\u001b[0m     torch_backward(surrogate_loss, retain_graph\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretain_graph)\n\u001b[1;32m    357\u001b[0m     elbo \u001b[39m=\u001b[39m torch_item(elbo)\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/infer/tracegraph_elbo.py:366\u001b[0m, in \u001b[0;36mTraceGraph_ELBO._loss_and_surrogate_loss\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    363\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m    364\u001b[0m surrogate_loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[0;32m--> 366\u001b[0m \u001b[39mfor\u001b[39;00m model_trace, guide_trace \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_traces(model, guide, args, kwargs):\n\u001b[1;32m    367\u001b[0m     lp, slp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_loss_and_surrogate_loss_particle(model_trace, guide_trace)\n\u001b[1;32m    368\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m lp\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/infer/elbo.py:237\u001b[0m, in \u001b[0;36mELBO._get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_particles):\n\u001b[0;32m--> 237\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_trace(model, guide, args, kwargs)\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/infer/tracegraph_elbo.py:319\u001b[0m, in \u001b[0;36mTraceGraph_ELBO._get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[39mReturns a single trace from the guide, and the model that is run\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[39magainst it.\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[39mwith\u001b[39;00m TrackNonReparam():\n\u001b[0;32m--> 319\u001b[0m     model_trace, guide_trace \u001b[39m=\u001b[39m get_importance_trace(\n\u001b[1;32m    320\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mdense\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_plate_nesting, model, guide, args, kwargs\n\u001b[1;32m    321\u001b[0m     )\n\u001b[1;32m    322\u001b[0m \u001b[39mif\u001b[39;00m is_validation_enabled():\n\u001b[1;32m    323\u001b[0m     check_if_enumerated(guide_trace)\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/infer/enum.py:65\u001b[0m, in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[39mif\u001b[39;00m detach:\n\u001b[1;32m     64\u001b[0m         guide_trace\u001b[39m.\u001b[39mdetach_()\n\u001b[0;32m---> 65\u001b[0m     model_trace \u001b[39m=\u001b[39m poutine\u001b[39m.\u001b[39;49mtrace(\n\u001b[1;32m     66\u001b[0m         poutine\u001b[39m.\u001b[39;49mreplay(model, trace\u001b[39m=\u001b[39;49mguide_trace), graph_type\u001b[39m=\u001b[39;49mgraph_type\n\u001b[1;32m     67\u001b[0m     )\u001b[39m.\u001b[39;49mget_trace(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     69\u001b[0m \u001b[39mif\u001b[39;00m is_validation_enabled():\n\u001b[1;32m     70\u001b[0m     check_model_guide_match(model_trace, guide_trace, max_plate_nesting)\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py:198\u001b[0m, in \u001b[0;36mTraceHandler.get_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_trace\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    191\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[39m    :returns: data structure\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[39m    :rtype: pyro.poutine.Trace\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39m    Calls this poutine and returns its trace instead of the function's return value.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    199\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mget_trace()\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py:180\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m         exc \u001b[39m=\u001b[39m exc_type(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(exc_value, shapes))\n\u001b[1;32m    179\u001b[0m         exc \u001b[39m=\u001b[39m exc\u001b[39m.\u001b[39mwith_traceback(traceback)\n\u001b[0;32m--> 180\u001b[0m         \u001b[39mraise\u001b[39;00m exc \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39madd_node(\n\u001b[1;32m    182\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m_RETURN\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_RETURN\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreturn\u001b[39m\u001b[39m\"\u001b[39m, value\u001b[39m=\u001b[39mret\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    184\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py:174\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39madd_node(\n\u001b[1;32m    171\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m_INPUT\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_INPUT\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs\n\u001b[1;32m    172\u001b[0m )\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    176\u001b[0m     exc_type, exc_value, traceback \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_context_wrap\u001b[39m(context, fn, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     11\u001b[0m     \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/nn/module.py:449\u001b[0m, in \u001b[0;36mPyroModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    448\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context:\n\u001b[0;32m--> 449\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    450\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    451\u001b[0m         pyro\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalidate_poutine\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context\u001b[39m.\u001b[39mactive\n\u001b[1;32m    453\u001b[0m         \u001b[39mand\u001b[39;00m _is_module_local_param_enabled()\n\u001b[1;32m    454\u001b[0m     ):\n\u001b[1;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_module_local_param_usage()\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/module.py:201\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_unimplemented\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39minput\u001b[39m: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Defines the computation performed at every call.\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \n\u001b[1;32m    193\u001b[0m \u001b[39m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: \nTrace Shapes:\n Param Sites:\nSample Sites:"
     ]
    }
   ],
   "source": [
    "model.svi.step(grp_descrp, logic_reduce,grp_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mmodules():\n\u001b[0;32m----> 2\u001b[0m     m\u001b[39m.\u001b[39;49mmodel(data_batch[\u001b[39m0\u001b[39;49m][\u001b[39m10\u001b[39;49m][\u001b[39m0\u001b[39;49m], data_batch[\u001b[39m0\u001b[39;49m][\u001b[39m10\u001b[39;49m][\u001b[39m0\u001b[39;49m], data_batch[\u001b[39m0\u001b[39;49m][\u001b[39m12\u001b[39;49m][\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/nn/module.py:449\u001b[0m, in \u001b[0;36mPyroModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    448\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context:\n\u001b[0;32m--> 449\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    450\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    451\u001b[0m         pyro\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalidate_poutine\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context\u001b[39m.\u001b[39mactive\n\u001b[1;32m    453\u001b[0m         \u001b[39mand\u001b[39;00m _is_module_local_param_enabled()\n\u001b[1;32m    454\u001b[0m     ):\n\u001b[1;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_module_local_param_usage()\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/module.py:201\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_unimplemented\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39minput\u001b[39m: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Defines the computation performed at every call.\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \n\u001b[1;32m    193\u001b[0m \u001b[39m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[39m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for m in model.modules():\n",
    "    m.model(data_batch[0][10][0], data_batch[0][10][0], data_batch[0][12][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Double",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mmodel(data_batch[\u001b[39m0\u001b[39;49m][\u001b[39m10\u001b[39;49m], data_batch[\u001b[39m0\u001b[39;49m][\u001b[39m12\u001b[39;49m])\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/nn/module.py:449\u001b[0m, in \u001b[0;36mPyroModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    448\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context:\n\u001b[0;32m--> 449\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    450\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    451\u001b[0m         pyro\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalidate_poutine\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context\u001b[39m.\u001b[39mactive\n\u001b[1;32m    453\u001b[0m         \u001b[39mand\u001b[39;00m _is_module_local_param_enabled()\n\u001b[1;32m    454\u001b[0m     ):\n\u001b[1;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_module_local_param_usage()\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/media/sf_work/projects/forks/aenet-PyTorch/src/network.py:76\u001b[0m, in \u001b[0;36mNetAtom.forward\u001b[0;34m(self, grp_descrp, logic_reduce)\u001b[0m\n\u001b[1;32m     74\u001b[0m partial_E_ann \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspecies))]\n\u001b[1;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m iesp \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspecies)):\n\u001b[0;32m---> 76\u001b[0m \tpartial_E_ann[iesp] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunctions[iesp](grp_descrp[iesp])\n\u001b[1;32m     78\u001b[0m \u001b[39m# Gather back all atoms corresponding to the same strucuture from partial_E_ann\u001b[39;00m\n\u001b[1;32m     79\u001b[0m list_E_ann \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros( (\u001b[39mlen\u001b[39m(logic_reduce[\u001b[39m0\u001b[39m])), device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice )\u001b[39m.\u001b[39mdouble()\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/nn/module.py:449\u001b[0m, in \u001b[0;36mPyroModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    448\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context:\n\u001b[0;32m--> 449\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    450\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    451\u001b[0m         pyro\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalidate_poutine\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context\u001b[39m.\u001b[39mactive\n\u001b[1;32m    453\u001b[0m         \u001b[39mand\u001b[39;00m _is_module_local_param_enabled()\n\u001b[1;32m    454\u001b[0m     ):\n\u001b[1;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_module_local_param_usage()\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/nn/module.py:449\u001b[0m, in \u001b[0;36mPyroModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    448\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context:\n\u001b[0;32m--> 449\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    450\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    451\u001b[0m         pyro\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalidate_poutine\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context\u001b[39m.\u001b[39mactive\n\u001b[1;32m    453\u001b[0m         \u001b[39mand\u001b[39;00m _is_module_local_param_enabled()\n\u001b[1;32m    454\u001b[0m     ):\n\u001b[1;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_module_local_param_usage()\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Double"
     ]
    }
   ],
   "source": [
    "model.model(data_batch[0][10], data_batch[0][12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_batch in grouped_train_loader:\n",
    "    grp_descrp, grp_energy, logic_reduce, grp_N_atom = data_batch[0][10], data_batch[0][11], data_batch[0][12], data_batch[0][14]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([27., 27., 27., 27.], dtype=torch.float64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_N_atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([108, 52])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grp_descrp[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Float but found Double\n                              Trace Shapes:        \n                               Param Sites:        \n                              Sample Sites:        \nmodel.functions.0.Linear_Sp1_F1.weight dist | 15 52\n                                      value | 15 52\n  model.functions.0.Linear_Sp1_F1.bias dist | 15   \n                                      value | 15   \nTrace Shapes:\n Param Sites:\nSample Sites:",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py:174\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/nn/module.py:449\u001b[0m, in \u001b[0;36mPyroModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context:\n\u001b[0;32m--> 449\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    450\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    451\u001b[0m     pyro\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalidate_poutine\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context\u001b[39m.\u001b[39mactive\n\u001b[1;32m    453\u001b[0m     \u001b[39mand\u001b[39;00m _is_module_local_param_enabled()\n\u001b[1;32m    454\u001b[0m ):\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "File \u001b[0;32m/media/sf_work/projects/forks/aenet-PyTorch/src/network.py:76\u001b[0m, in \u001b[0;36mNetAtom.forward\u001b[0;34m(self, grp_descrp, logic_reduce)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m iesp \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspecies)):\n\u001b[0;32m---> 76\u001b[0m \tpartial_E_ann[iesp] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunctions[iesp](grp_descrp[iesp])\n\u001b[1;32m     78\u001b[0m \u001b[39m# Gather back all atoms corresponding to the same strucuture from partial_E_ann\u001b[39;00m\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/nn/module.py:449\u001b[0m, in \u001b[0;36mPyroModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context:\n\u001b[0;32m--> 449\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    450\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    451\u001b[0m     pyro\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalidate_poutine\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context\u001b[39m.\u001b[39mactive\n\u001b[1;32m    453\u001b[0m     \u001b[39mand\u001b[39;00m _is_module_local_param_enabled()\n\u001b[1;32m    454\u001b[0m ):\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/nn/module.py:449\u001b[0m, in \u001b[0;36mPyroModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context:\n\u001b[0;32m--> 449\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    450\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    451\u001b[0m     pyro\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalidate_poutine\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context\u001b[39m.\u001b[39mactive\n\u001b[1;32m    453\u001b[0m     \u001b[39mand\u001b[39;00m _is_module_local_param_enabled()\n\u001b[1;32m    454\u001b[0m ):\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Double",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py:174\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/nn/module.py:449\u001b[0m, in \u001b[0;36mPyroModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context:\n\u001b[0;32m--> 449\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    450\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    451\u001b[0m     pyro\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalidate_poutine\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context\u001b[39m.\u001b[39mactive\n\u001b[1;32m    453\u001b[0m     \u001b[39mand\u001b[39;00m _is_module_local_param_enabled()\n\u001b[1;32m    454\u001b[0m ):\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/infer/autoguide/guides.py:759\u001b[0m, in \u001b[0;36mAutoContinuous.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprototype_trace \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 759\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_prototype(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    761\u001b[0m latent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_latent(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/infer/autoguide/guides.py:935\u001b[0m, in \u001b[0;36mAutoDiagonalNormal._setup_prototype\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_setup_prototype\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 935\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_setup_prototype(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    936\u001b[0m     \u001b[39m# Initialize guide params\u001b[39;00m\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/infer/autoguide/guides.py:636\u001b[0m, in \u001b[0;36mAutoContinuous._setup_prototype\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_setup_prototype\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 636\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_setup_prototype(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    637\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unconstrained_shapes \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/infer/autoguide/guides.py:157\u001b[0m, in \u001b[0;36mAutoGuide._setup_prototype\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m model \u001b[39m=\u001b[39m poutine\u001b[39m.\u001b[39mblock(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prototype_hide_fn)\n\u001b[0;32m--> 157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprototype_trace \u001b[39m=\u001b[39m poutine\u001b[39m.\u001b[39;49mblock(poutine\u001b[39m.\u001b[39;49mtrace(model)\u001b[39m.\u001b[39;49mget_trace)(\n\u001b[1;32m    158\u001b[0m     \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    159\u001b[0m )\n\u001b[1;32m    160\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaster \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py:198\u001b[0m, in \u001b[0;36mTraceHandler.get_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[39m:returns: data structure\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[39m:rtype: pyro.poutine.Trace\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39mCalls this poutine and returns its trace instead of the function's return value.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    199\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mget_trace()\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py:180\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     exc \u001b[39m=\u001b[39m exc\u001b[39m.\u001b[39mwith_traceback(traceback)\n\u001b[0;32m--> 180\u001b[0m     \u001b[39mraise\u001b[39;00m exc \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39madd_node(\n\u001b[1;32m    182\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m_RETURN\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_RETURN\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreturn\u001b[39m\u001b[39m\"\u001b[39m, value\u001b[39m=\u001b[39mret\n\u001b[1;32m    183\u001b[0m )\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py:174\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/nn/module.py:449\u001b[0m, in \u001b[0;36mPyroModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context:\n\u001b[0;32m--> 449\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    450\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    451\u001b[0m     pyro\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalidate_poutine\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context\u001b[39m.\u001b[39mactive\n\u001b[1;32m    453\u001b[0m     \u001b[39mand\u001b[39;00m _is_module_local_param_enabled()\n\u001b[1;32m    454\u001b[0m ):\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "File \u001b[0;32m/media/sf_work/projects/forks/aenet-PyTorch/src/network.py:76\u001b[0m, in \u001b[0;36mNetAtom.forward\u001b[0;34m(self, grp_descrp, logic_reduce)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m iesp \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspecies)):\n\u001b[0;32m---> 76\u001b[0m \tpartial_E_ann[iesp] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunctions[iesp](grp_descrp[iesp])\n\u001b[1;32m     78\u001b[0m \u001b[39m# Gather back all atoms corresponding to the same strucuture from partial_E_ann\u001b[39;00m\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/nn/module.py:449\u001b[0m, in \u001b[0;36mPyroModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context:\n\u001b[0;32m--> 449\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    450\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    451\u001b[0m     pyro\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalidate_poutine\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context\u001b[39m.\u001b[39mactive\n\u001b[1;32m    453\u001b[0m     \u001b[39mand\u001b[39;00m _is_module_local_param_enabled()\n\u001b[1;32m    454\u001b[0m ):\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    142\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/nn/module.py:449\u001b[0m, in \u001b[0;36mPyroModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context:\n\u001b[0;32m--> 449\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    450\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    451\u001b[0m     pyro\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalidate_poutine\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context\u001b[39m.\u001b[39mactive\n\u001b[1;32m    453\u001b[0m     \u001b[39mand\u001b[39;00m _is_module_local_param_enabled()\n\u001b[1;32m    454\u001b[0m ):\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Double\n                              Trace Shapes:        \n                               Param Sites:        \n                              Sample Sites:        \nmodel.functions.0.Linear_Sp1_F1.weight dist | 15 52\n                                      value | 15 52\n  model.functions.0.Linear_Sp1_F1.bias dist | 15   \n                                      value | 15   ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m data_batch \u001b[39min\u001b[39;00m grouped_train_loader:\n\u001b[0;32m----> 2\u001b[0m     model\u001b[39m.\u001b[39;49mstep(data_batch[\u001b[39m0\u001b[39;49m][\u001b[39m10\u001b[39;49m], data_batch[\u001b[39m0\u001b[39;49m][\u001b[39m12\u001b[39;49m])\n",
      "File \u001b[0;32m/media/sf_work/projects/forks/aenet-PyTorch/src/bayesian_network.py:42\u001b[0m, in \u001b[0;36mBayesianNetAtoms.step\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[0;32m---> 42\u001b[0m \t\u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msvi\u001b[39m.\u001b[39;49mstep(X, y)\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/infer/svi.py:145\u001b[0m, in \u001b[0;36mSVI.step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[39m# get loss and compute gradients\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39mwith\u001b[39;00m poutine\u001b[39m.\u001b[39mtrace(param_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m param_capture:\n\u001b[0;32m--> 145\u001b[0m     loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss_and_grads(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mguide, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    147\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\n\u001b[1;32m    148\u001b[0m     site[\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39munconstrained() \u001b[39mfor\u001b[39;00m site \u001b[39min\u001b[39;00m param_capture\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39mnodes\u001b[39m.\u001b[39mvalues()\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[39m# actually perform gradient steps\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001b[39;00m\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/infer/trace_elbo.py:140\u001b[0m, in \u001b[0;36mTrace_ELBO.loss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n\u001b[1;32m    139\u001b[0m \u001b[39m# grab a trace from the generator\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[39mfor\u001b[39;00m model_trace, guide_trace \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_traces(model, guide, args, kwargs):\n\u001b[1;32m    141\u001b[0m     loss_particle, surrogate_loss_particle \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_differentiable_loss_particle(\n\u001b[1;32m    142\u001b[0m         model_trace, guide_trace\n\u001b[1;32m    143\u001b[0m     )\n\u001b[1;32m    144\u001b[0m     loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_particle \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_particles\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/infer/elbo.py:237\u001b[0m, in \u001b[0;36mELBO._get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_particles):\n\u001b[0;32m--> 237\u001b[0m         \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_trace(model, guide, args, kwargs)\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/infer/trace_elbo.py:57\u001b[0m, in \u001b[0;36mTrace_ELBO._get_trace\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_trace\u001b[39m(\u001b[39mself\u001b[39m, model, guide, args, kwargs):\n\u001b[1;32m     53\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[39m    Returns a single trace from the guide, and the model that is run\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[39m    against it.\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m     model_trace, guide_trace \u001b[39m=\u001b[39m get_importance_trace(\n\u001b[1;32m     58\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mflat\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_plate_nesting, model, guide, args, kwargs\n\u001b[1;32m     59\u001b[0m     )\n\u001b[1;32m     60\u001b[0m     \u001b[39mif\u001b[39;00m is_validation_enabled():\n\u001b[1;32m     61\u001b[0m         check_if_enumerated(guide_trace)\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/infer/enum.py:60\u001b[0m, in \u001b[0;36mget_importance_trace\u001b[0;34m(graph_type, max_plate_nesting, model, guide, args, kwargs, detach)\u001b[0m\n\u001b[1;32m     58\u001b[0m     model_trace, guide_trace \u001b[39m=\u001b[39m unwrapped_guide\u001b[39m.\u001b[39mget_traces()\n\u001b[1;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     guide_trace \u001b[39m=\u001b[39m poutine\u001b[39m.\u001b[39;49mtrace(guide, graph_type\u001b[39m=\u001b[39;49mgraph_type)\u001b[39m.\u001b[39;49mget_trace(\n\u001b[1;32m     61\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     63\u001b[0m     \u001b[39mif\u001b[39;00m detach:\n\u001b[1;32m     64\u001b[0m         guide_trace\u001b[39m.\u001b[39mdetach_()\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py:198\u001b[0m, in \u001b[0;36mTraceHandler.get_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_trace\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    191\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[39m    :returns: data structure\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[39m    :rtype: pyro.poutine.Trace\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39m    Calls this poutine and returns its trace instead of the function's return value.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    199\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mget_trace()\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py:180\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m         exc \u001b[39m=\u001b[39m exc_type(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(exc_value, shapes))\n\u001b[1;32m    179\u001b[0m         exc \u001b[39m=\u001b[39m exc\u001b[39m.\u001b[39mwith_traceback(traceback)\n\u001b[0;32m--> 180\u001b[0m         \u001b[39mraise\u001b[39;00m exc \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39madd_node(\n\u001b[1;32m    182\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m_RETURN\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_RETURN\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreturn\u001b[39m\u001b[39m\"\u001b[39m, value\u001b[39m=\u001b[39mret\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    184\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py:174\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39madd_node(\n\u001b[1;32m    171\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m_INPUT\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_INPUT\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs\n\u001b[1;32m    172\u001b[0m )\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    176\u001b[0m     exc_type, exc_value, traceback \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/nn/module.py:449\u001b[0m, in \u001b[0;36mPyroModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    448\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context:\n\u001b[0;32m--> 449\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    450\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    451\u001b[0m         pyro\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalidate_poutine\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context\u001b[39m.\u001b[39mactive\n\u001b[1;32m    453\u001b[0m         \u001b[39mand\u001b[39;00m _is_module_local_param_enabled()\n\u001b[1;32m    454\u001b[0m     ):\n\u001b[1;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_module_local_param_usage()\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/infer/autoguide/guides.py:759\u001b[0m, in \u001b[0;36mAutoContinuous.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[39m# if we've never run the model before, do so now so we can inspect the model structure\u001b[39;00m\n\u001b[1;32m    758\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprototype_trace \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 759\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setup_prototype(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    761\u001b[0m latent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_latent(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    762\u001b[0m plates \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_plates(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/infer/autoguide/guides.py:935\u001b[0m, in \u001b[0;36mAutoDiagonalNormal._setup_prototype\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_setup_prototype\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 935\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_setup_prototype(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    936\u001b[0m     \u001b[39m# Initialize guide params\u001b[39;00m\n\u001b[1;32m    937\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mParameter(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_loc())\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/infer/autoguide/guides.py:636\u001b[0m, in \u001b[0;36mAutoContinuous._setup_prototype\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_setup_prototype\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 636\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_setup_prototype(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    637\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_unconstrained_shapes \u001b[39m=\u001b[39m {}\n\u001b[1;32m    638\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cond_indep_stacks \u001b[39m=\u001b[39m {}\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/infer/autoguide/guides.py:157\u001b[0m, in \u001b[0;36mAutoGuide._setup_prototype\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_setup_prototype\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    155\u001b[0m     \u001b[39m# run the model so we can inspect its structure\u001b[39;00m\n\u001b[1;32m    156\u001b[0m     model \u001b[39m=\u001b[39m poutine\u001b[39m.\u001b[39mblock(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prototype_hide_fn)\n\u001b[0;32m--> 157\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprototype_trace \u001b[39m=\u001b[39m poutine\u001b[39m.\u001b[39;49mblock(poutine\u001b[39m.\u001b[39;49mtrace(model)\u001b[39m.\u001b[39;49mget_trace)(\n\u001b[1;32m    158\u001b[0m         \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    159\u001b[0m     )\n\u001b[1;32m    160\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaster \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaster()\u001b[39m.\u001b[39m_check_prototype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprototype_trace)\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_context_wrap\u001b[39m(context, fn, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     11\u001b[0m     \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py:198\u001b[0m, in \u001b[0;36mTraceHandler.get_trace\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_trace\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    191\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[39m    :returns: data structure\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[39m    :rtype: pyro.poutine.Trace\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39m    Calls this poutine and returns its trace instead of the function's return value.\u001b[39;00m\n\u001b[1;32m    197\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 198\u001b[0m     \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    199\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mget_trace()\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py:180\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m         exc \u001b[39m=\u001b[39m exc_type(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(exc_value, shapes))\n\u001b[1;32m    179\u001b[0m         exc \u001b[39m=\u001b[39m exc\u001b[39m.\u001b[39mwith_traceback(traceback)\n\u001b[0;32m--> 180\u001b[0m         \u001b[39mraise\u001b[39;00m exc \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    181\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39madd_node(\n\u001b[1;32m    182\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m_RETURN\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_RETURN\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreturn\u001b[39m\u001b[39m\"\u001b[39m, value\u001b[39m=\u001b[39mret\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    184\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/trace_messenger.py:174\u001b[0m, in \u001b[0;36mTraceHandler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmsngr\u001b[39m.\u001b[39mtrace\u001b[39m.\u001b[39madd_node(\n\u001b[1;32m    171\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m_INPUT\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_INPUT\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs\n\u001b[1;32m    172\u001b[0m )\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    175\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    176\u001b[0m     exc_type, exc_value, traceback \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_context_wrap\u001b[39m(context, fn, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     11\u001b[0m     \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/poutine/messenger.py:12\u001b[0m, in \u001b[0;36m_context_wrap\u001b[0;34m(context, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_context_wrap\u001b[39m(context, fn, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     11\u001b[0m     \u001b[39mwith\u001b[39;00m context:\n\u001b[0;32m---> 12\u001b[0m         \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/nn/module.py:449\u001b[0m, in \u001b[0;36mPyroModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    448\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context:\n\u001b[0;32m--> 449\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    450\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    451\u001b[0m         pyro\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalidate_poutine\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context\u001b[39m.\u001b[39mactive\n\u001b[1;32m    453\u001b[0m         \u001b[39mand\u001b[39;00m _is_module_local_param_enabled()\n\u001b[1;32m    454\u001b[0m     ):\n\u001b[1;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_module_local_param_usage()\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/media/sf_work/projects/forks/aenet-PyTorch/src/network.py:76\u001b[0m, in \u001b[0;36mNetAtom.forward\u001b[0;34m(self, grp_descrp, logic_reduce)\u001b[0m\n\u001b[1;32m     74\u001b[0m partial_E_ann \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspecies))]\n\u001b[1;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m iesp \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspecies)):\n\u001b[0;32m---> 76\u001b[0m \tpartial_E_ann[iesp] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunctions[iesp](grp_descrp[iesp])\n\u001b[1;32m     78\u001b[0m \u001b[39m# Gather back all atoms corresponding to the same strucuture from partial_E_ann\u001b[39;00m\n\u001b[1;32m     79\u001b[0m list_E_ann \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros( (\u001b[39mlen\u001b[39m(logic_reduce[\u001b[39m0\u001b[39m])), device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice )\u001b[39m.\u001b[39mdouble()\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/nn/module.py:449\u001b[0m, in \u001b[0;36mPyroModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    448\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context:\n\u001b[0;32m--> 449\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    450\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    451\u001b[0m         pyro\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalidate_poutine\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context\u001b[39m.\u001b[39mactive\n\u001b[1;32m    453\u001b[0m         \u001b[39mand\u001b[39;00m _is_module_local_param_enabled()\n\u001b[1;32m    454\u001b[0m     ):\n\u001b[1;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_module_local_param_usage()\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/pyro/nn/module.py:449\u001b[0m, in \u001b[0;36mPyroModule.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    448\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context:\n\u001b[0;32m--> 449\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    450\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    451\u001b[0m         pyro\u001b[39m.\u001b[39msettings\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mvalidate_poutine\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    452\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pyro_context\u001b[39m.\u001b[39mactive\n\u001b[1;32m    453\u001b[0m         \u001b[39mand\u001b[39;00m _is_module_local_param_enabled()\n\u001b[1;32m    454\u001b[0m     ):\n\u001b[1;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_module_local_param_usage()\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.venvs/gen/lib/python3.10/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Float but found Double\n                              Trace Shapes:        \n                               Param Sites:        \n                              Sample Sites:        \nmodel.functions.0.Linear_Sp1_F1.weight dist | 15 52\n                                      value | 15 52\n  model.functions.0.Linear_Sp1_F1.bias dist | 15   \n                                      value | 15   \nTrace Shapes:\n Param Sites:\nSample Sites:"
     ]
    }
   ],
   "source": [
    "for data_batch in grouped_train_loader:\n",
    "    model.step(data_batch[0][10], data_batch[0][12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.0789,  0.7212, -1.5706,  ...,  1.3901,  1.2308,  0.2393],\n",
       "         [-1.0732,  0.9951,  0.0450,  ...,  0.4152, -0.1812,  0.9815],\n",
       "         [ 0.3986, -0.4489,  0.1622,  ..., -0.2772, -0.7212,  0.4384],\n",
       "         ...,\n",
       "         [-0.6189, -2.1412,  1.5223,  ..., -1.7583, -1.2087, -2.4926],\n",
       "         [ 1.6111,  0.4451, -0.4222,  ...,  0.3068,  0.3127, -0.5332],\n",
       "         [-0.1283, -0.6618, -0.9102,  ...,  0.5214, -0.0743,  0.6787]],\n",
       "        dtype=torch.float64),\n",
       " tensor([], size=(0, 52), dtype=torch.float64)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch[0][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
